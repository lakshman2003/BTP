{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iHvm-Sjn4YSQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "JWGUmsl04YSR",
    "outputId": "08652394-b429-49ae-f6b1-c2f9d6d678d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADANIENT</th>\n",
       "      <th>BRITANNIA</th>\n",
       "      <th>CIPLA</th>\n",
       "      <th>COALINDIA</th>\n",
       "      <th>DIVISLAB</th>\n",
       "      <th>DRREDDY</th>\n",
       "      <th>EICHERMOT</th>\n",
       "      <th>GRASIM</th>\n",
       "      <th>HCLTECH</th>\n",
       "      <th>HDFCBANK</th>\n",
       "      <th>...</th>\n",
       "      <th>TITAN</th>\n",
       "      <th>UPL</th>\n",
       "      <th>ULTRACEMCO</th>\n",
       "      <th>WIPRO</th>\n",
       "      <th>AXISBANK</th>\n",
       "      <th>BAJAJ-AUTO</th>\n",
       "      <th>BAJFINANCE</th>\n",
       "      <th>BAJAJFINSV</th>\n",
       "      <th>BPCL</th>\n",
       "      <th>BHARTIARTL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "      <td>3005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>633.341357</td>\n",
       "      <td>2156.886180</td>\n",
       "      <td>640.758956</td>\n",
       "      <td>155.561973</td>\n",
       "      <td>1797.518830</td>\n",
       "      <td>3185.517052</td>\n",
       "      <td>1949.238653</td>\n",
       "      <td>906.600425</td>\n",
       "      <td>527.752811</td>\n",
       "      <td>882.586093</td>\n",
       "      <td>...</td>\n",
       "      <td>1067.947571</td>\n",
       "      <td>411.988163</td>\n",
       "      <td>4182.339237</td>\n",
       "      <td>271.766160</td>\n",
       "      <td>553.570925</td>\n",
       "      <td>2500.942075</td>\n",
       "      <td>2717.654767</td>\n",
       "      <td>638.130098</td>\n",
       "      <td>245.003161</td>\n",
       "      <td>438.739002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1013.359215</td>\n",
       "      <td>1440.439963</td>\n",
       "      <td>254.767135</td>\n",
       "      <td>52.458191</td>\n",
       "      <td>1377.658824</td>\n",
       "      <td>1188.163520</td>\n",
       "      <td>1033.313968</td>\n",
       "      <td>495.868959</td>\n",
       "      <td>349.694835</td>\n",
       "      <td>469.192995</td>\n",
       "      <td>...</td>\n",
       "      <td>944.366754</td>\n",
       "      <td>219.584657</td>\n",
       "      <td>2126.307625</td>\n",
       "      <td>135.562967</td>\n",
       "      <td>228.244484</td>\n",
       "      <td>1167.232985</td>\n",
       "      <td>2609.157504</td>\n",
       "      <td>558.827643</td>\n",
       "      <td>115.421963</td>\n",
       "      <td>211.752147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.796553</td>\n",
       "      <td>186.168533</td>\n",
       "      <td>272.990204</td>\n",
       "      <td>75.514877</td>\n",
       "      <td>318.192383</td>\n",
       "      <td>1405.305420</td>\n",
       "      <td>137.076782</td>\n",
       "      <td>316.081879</td>\n",
       "      <td>74.488335</td>\n",
       "      <td>195.259384</td>\n",
       "      <td>...</td>\n",
       "      <td>162.429214</td>\n",
       "      <td>62.702530</td>\n",
       "      <td>1087.994873</td>\n",
       "      <td>111.145164</td>\n",
       "      <td>148.065018</td>\n",
       "      <td>996.573669</td>\n",
       "      <td>53.954967</td>\n",
       "      <td>40.620739</td>\n",
       "      <td>43.317684</td>\n",
       "      <td>205.996841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.255657</td>\n",
       "      <td>846.795044</td>\n",
       "      <td>454.789276</td>\n",
       "      <td>124.938423</td>\n",
       "      <td>683.712708</td>\n",
       "      <td>2284.340820</td>\n",
       "      <td>1376.775391</td>\n",
       "      <td>506.490631</td>\n",
       "      <td>315.875916</td>\n",
       "      <td>455.686371</td>\n",
       "      <td>...</td>\n",
       "      <td>330.461395</td>\n",
       "      <td>223.645325</td>\n",
       "      <td>2628.458984</td>\n",
       "      <td>186.984253</td>\n",
       "      <td>402.924896</td>\n",
       "      <td>1727.858765</td>\n",
       "      <td>378.976105</td>\n",
       "      <td>131.759201</td>\n",
       "      <td>147.589554</td>\n",
       "      <td>286.976349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.604172</td>\n",
       "      <td>2159.928955</td>\n",
       "      <td>572.538940</td>\n",
       "      <td>150.431915</td>\n",
       "      <td>1096.414551</td>\n",
       "      <td>2834.017334</td>\n",
       "      <td>2069.880127</td>\n",
       "      <td>739.326904</td>\n",
       "      <td>393.638824</td>\n",
       "      <td>890.442566</td>\n",
       "      <td>...</td>\n",
       "      <td>800.377502</td>\n",
       "      <td>437.294769</td>\n",
       "      <td>3843.958008</td>\n",
       "      <td>211.735443</td>\n",
       "      <td>534.344177</td>\n",
       "      <td>2261.286377</td>\n",
       "      <td>1784.374634</td>\n",
       "      <td>511.523285</td>\n",
       "      <td>277.779755</td>\n",
       "      <td>336.453400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>804.621216</td>\n",
       "      <td>3354.730469</td>\n",
       "      <td>811.459656</td>\n",
       "      <td>168.762100</td>\n",
       "      <td>3263.449951</td>\n",
       "      <td>4232.393555</td>\n",
       "      <td>2688.486084</td>\n",
       "      <td>1240.489990</td>\n",
       "      <td>830.965881</td>\n",
       "      <td>1349.573242</td>\n",
       "      <td>...</td>\n",
       "      <td>1478.045776</td>\n",
       "      <td>574.535400</td>\n",
       "      <td>5554.201172</td>\n",
       "      <td>378.757324</td>\n",
       "      <td>726.750977</td>\n",
       "      <td>3047.652588</td>\n",
       "      <td>5173.579590</td>\n",
       "      <td>968.819397</td>\n",
       "      <td>330.712097</td>\n",
       "      <td>534.702454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4163.219727</td>\n",
       "      <td>5361.299805</td>\n",
       "      <td>1487.449951</td>\n",
       "      <td>474.533630</td>\n",
       "      <td>5288.634277</td>\n",
       "      <td>6449.600098</td>\n",
       "      <td>4180.350098</td>\n",
       "      <td>2254.899902</td>\n",
       "      <td>1686.400024</td>\n",
       "      <td>1728.199951</td>\n",
       "      <td>...</td>\n",
       "      <td>3866.649902</td>\n",
       "      <td>818.247742</td>\n",
       "      <td>10503.049805</td>\n",
       "      <td>711.108215</td>\n",
       "      <td>1136.949951</td>\n",
       "      <td>8879.049805</td>\n",
       "      <td>8168.549805</td>\n",
       "      <td>1904.959839</td>\n",
       "      <td>657.599976</td>\n",
       "      <td>1199.699951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ADANIENT    BRITANNIA        CIPLA    COALINDIA     DIVISLAB  \\\n",
       "count  3005.000000  3005.000000  3005.000000  3005.000000  3005.000000   \n",
       "mean    633.341357  2156.886180   640.758956   155.561973  1797.518830   \n",
       "std    1013.359215  1440.439963   254.767135    52.458191  1377.658824   \n",
       "min      18.796553   186.168533   272.990204    75.514877   318.192383   \n",
       "25%      42.255657   846.795044   454.789276   124.938423   683.712708   \n",
       "50%      91.604172  2159.928955   572.538940   150.431915  1096.414551   \n",
       "75%     804.621216  3354.730469   811.459656   168.762100  3263.449951   \n",
       "max    4163.219727  5361.299805  1487.449951   474.533630  5288.634277   \n",
       "\n",
       "           DRREDDY    EICHERMOT       GRASIM      HCLTECH     HDFCBANK  ...  \\\n",
       "count  3005.000000  3005.000000  3005.000000  3005.000000  3005.000000  ...   \n",
       "mean   3185.517052  1949.238653   906.600425   527.752811   882.586093  ...   \n",
       "std    1188.163520  1033.313968   495.868959   349.694835   469.192995  ...   \n",
       "min    1405.305420   137.076782   316.081879    74.488335   195.259384  ...   \n",
       "25%    2284.340820  1376.775391   506.490631   315.875916   455.686371  ...   \n",
       "50%    2834.017334  2069.880127   739.326904   393.638824   890.442566  ...   \n",
       "75%    4232.393555  2688.486084  1240.489990   830.965881  1349.573242  ...   \n",
       "max    6449.600098  4180.350098  2254.899902  1686.400024  1728.199951  ...   \n",
       "\n",
       "             TITAN          UPL    ULTRACEMCO        WIPRO     AXISBANK  \\\n",
       "count  3005.000000  3005.000000   3005.000000  3005.000000  3005.000000   \n",
       "mean   1067.947571   411.988163   4182.339237   271.766160   553.570925   \n",
       "std     944.366754   219.584657   2126.307625   135.562967   228.244484   \n",
       "min     162.429214    62.702530   1087.994873   111.145164   148.065018   \n",
       "25%     330.461395   223.645325   2628.458984   186.984253   402.924896   \n",
       "50%     800.377502   437.294769   3843.958008   211.735443   534.344177   \n",
       "75%    1478.045776   574.535400   5554.201172   378.757324   726.750977   \n",
       "max    3866.649902   818.247742  10503.049805   711.108215  1136.949951   \n",
       "\n",
       "        BAJAJ-AUTO   BAJFINANCE   BAJAJFINSV         BPCL   BHARTIARTL  \n",
       "count  3005.000000  3005.000000  3005.000000  3005.000000  3005.000000  \n",
       "mean   2500.942075  2717.654767   638.130098   245.003161   438.739002  \n",
       "std    1167.232985  2609.157504   558.827643   115.421963   211.752147  \n",
       "min     996.573669    53.954967    40.620739    43.317684   205.996841  \n",
       "25%    1727.858765   378.976105   131.759201   147.589554   286.976349  \n",
       "50%    2261.286377  1784.374634   511.523285   277.779755   336.453400  \n",
       "75%    3047.652588  5173.579590   968.819397   330.712097   534.702454  \n",
       "max    8879.049805  8168.549805  1904.959839   657.599976  1199.699951  \n",
       "\n",
       "[8 rows x 47 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.read_csv('Closed_price_Data.csv')\n",
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "dNZrDOdn5oFg",
    "outputId": "56cd4103-a590-4098-e12b-aba804321fa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ADANIENT</th>\n",
       "      <th>BRITANNIA</th>\n",
       "      <th>CIPLA</th>\n",
       "      <th>COALINDIA</th>\n",
       "      <th>DIVISLAB</th>\n",
       "      <th>DRREDDY</th>\n",
       "      <th>EICHERMOT</th>\n",
       "      <th>GRASIM</th>\n",
       "      <th>HCLTECH</th>\n",
       "      <th>...</th>\n",
       "      <th>TITAN</th>\n",
       "      <th>UPL</th>\n",
       "      <th>ULTRACEMCO</th>\n",
       "      <th>WIPRO</th>\n",
       "      <th>AXISBANK</th>\n",
       "      <th>BAJAJ-AUTO</th>\n",
       "      <th>BAJFINANCE</th>\n",
       "      <th>BAJAJFINSV</th>\n",
       "      <th>BPCL</th>\n",
       "      <th>BHARTIARTL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>37.360767</td>\n",
       "      <td>189.653061</td>\n",
       "      <td>302.981354</td>\n",
       "      <td>119.517441</td>\n",
       "      <td>347.175476</td>\n",
       "      <td>1429.439087</td>\n",
       "      <td>138.428375</td>\n",
       "      <td>344.951599</td>\n",
       "      <td>74.488335</td>\n",
       "      <td>...</td>\n",
       "      <td>164.542953</td>\n",
       "      <td>72.786537</td>\n",
       "      <td>1103.534058</td>\n",
       "      <td>133.781372</td>\n",
       "      <td>148.065018</td>\n",
       "      <td>1033.813477</td>\n",
       "      <td>55.180374</td>\n",
       "      <td>40.790676</td>\n",
       "      <td>45.257984</td>\n",
       "      <td>292.015533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>37.192513</td>\n",
       "      <td>190.077988</td>\n",
       "      <td>309.782532</td>\n",
       "      <td>125.279831</td>\n",
       "      <td>348.197083</td>\n",
       "      <td>1462.634155</td>\n",
       "      <td>144.936447</td>\n",
       "      <td>350.144135</td>\n",
       "      <td>76.305084</td>\n",
       "      <td>...</td>\n",
       "      <td>168.676483</td>\n",
       "      <td>75.050377</td>\n",
       "      <td>1124.237427</td>\n",
       "      <td>139.648972</td>\n",
       "      <td>156.029007</td>\n",
       "      <td>1047.125977</td>\n",
       "      <td>56.053715</td>\n",
       "      <td>42.358997</td>\n",
       "      <td>44.528019</td>\n",
       "      <td>303.745300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>36.001732</td>\n",
       "      <td>190.460495</td>\n",
       "      <td>312.521851</td>\n",
       "      <td>125.088425</td>\n",
       "      <td>348.197083</td>\n",
       "      <td>1449.109985</td>\n",
       "      <td>141.251953</td>\n",
       "      <td>343.417999</td>\n",
       "      <td>79.181679</td>\n",
       "      <td>...</td>\n",
       "      <td>167.032486</td>\n",
       "      <td>75.709450</td>\n",
       "      <td>1091.963257</td>\n",
       "      <td>140.235733</td>\n",
       "      <td>158.003708</td>\n",
       "      <td>998.816040</td>\n",
       "      <td>55.354130</td>\n",
       "      <td>40.620739</td>\n",
       "      <td>44.334942</td>\n",
       "      <td>293.328247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>34.571507</td>\n",
       "      <td>186.763428</td>\n",
       "      <td>316.441925</td>\n",
       "      <td>122.733643</td>\n",
       "      <td>343.089020</td>\n",
       "      <td>1440.412842</td>\n",
       "      <td>140.006805</td>\n",
       "      <td>342.733337</td>\n",
       "      <td>78.490944</td>\n",
       "      <td>...</td>\n",
       "      <td>165.764191</td>\n",
       "      <td>76.081985</td>\n",
       "      <td>1099.804443</td>\n",
       "      <td>139.129318</td>\n",
       "      <td>162.195297</td>\n",
       "      <td>1028.978882</td>\n",
       "      <td>55.514172</td>\n",
       "      <td>40.839226</td>\n",
       "      <td>43.317684</td>\n",
       "      <td>291.676758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>34.759171</td>\n",
       "      <td>188.314453</td>\n",
       "      <td>319.700897</td>\n",
       "      <td>121.776459</td>\n",
       "      <td>342.178436</td>\n",
       "      <td>1457.625366</td>\n",
       "      <td>138.280258</td>\n",
       "      <td>345.008636</td>\n",
       "      <td>79.020805</td>\n",
       "      <td>...</td>\n",
       "      <td>162.429214</td>\n",
       "      <td>76.110657</td>\n",
       "      <td>1100.282715</td>\n",
       "      <td>136.044586</td>\n",
       "      <td>159.000381</td>\n",
       "      <td>1020.676270</td>\n",
       "      <td>53.954967</td>\n",
       "      <td>40.960613</td>\n",
       "      <td>44.881233</td>\n",
       "      <td>279.947021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   ADANIENT   BRITANNIA       CIPLA   COALINDIA    DIVISLAB  \\\n",
       "0  2012-01-02  37.360767  189.653061  302.981354  119.517441  347.175476   \n",
       "1  2012-01-03  37.192513  190.077988  309.782532  125.279831  348.197083   \n",
       "2  2012-01-04  36.001732  190.460495  312.521851  125.088425  348.197083   \n",
       "3  2012-01-05  34.571507  186.763428  316.441925  122.733643  343.089020   \n",
       "4  2012-01-06  34.759171  188.314453  319.700897  121.776459  342.178436   \n",
       "\n",
       "       DRREDDY   EICHERMOT      GRASIM    HCLTECH  ...       TITAN        UPL  \\\n",
       "0  1429.439087  138.428375  344.951599  74.488335  ...  164.542953  72.786537   \n",
       "1  1462.634155  144.936447  350.144135  76.305084  ...  168.676483  75.050377   \n",
       "2  1449.109985  141.251953  343.417999  79.181679  ...  167.032486  75.709450   \n",
       "3  1440.412842  140.006805  342.733337  78.490944  ...  165.764191  76.081985   \n",
       "4  1457.625366  138.280258  345.008636  79.020805  ...  162.429214  76.110657   \n",
       "\n",
       "    ULTRACEMCO       WIPRO    AXISBANK   BAJAJ-AUTO  BAJFINANCE  BAJAJFINSV  \\\n",
       "0  1103.534058  133.781372  148.065018  1033.813477   55.180374   40.790676   \n",
       "1  1124.237427  139.648972  156.029007  1047.125977   56.053715   42.358997   \n",
       "2  1091.963257  140.235733  158.003708   998.816040   55.354130   40.620739   \n",
       "3  1099.804443  139.129318  162.195297  1028.978882   55.514172   40.839226   \n",
       "4  1100.282715  136.044586  159.000381  1020.676270   53.954967   40.960613   \n",
       "\n",
       "        BPCL  BHARTIARTL  \n",
       "0  45.257984  292.015533  \n",
       "1  44.528019  303.745300  \n",
       "2  44.334942  293.328247  \n",
       "3  43.317684  291.676758  \n",
       "4  44.881233  279.947021  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "juNfNZu87OKF",
    "outputId": "c36c17fe-c854-430f-9a7c-490b34a4f8cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ADANIENT</th>\n",
       "      <th>BRITANNIA</th>\n",
       "      <th>CIPLA</th>\n",
       "      <th>COALINDIA</th>\n",
       "      <th>DIVISLAB</th>\n",
       "      <th>DRREDDY</th>\n",
       "      <th>EICHERMOT</th>\n",
       "      <th>GRASIM</th>\n",
       "      <th>HCLTECH</th>\n",
       "      <th>...</th>\n",
       "      <th>TITAN</th>\n",
       "      <th>UPL</th>\n",
       "      <th>ULTRACEMCO</th>\n",
       "      <th>WIPRO</th>\n",
       "      <th>AXISBANK</th>\n",
       "      <th>BAJAJ-AUTO</th>\n",
       "      <th>BAJFINANCE</th>\n",
       "      <th>BAJAJFINSV</th>\n",
       "      <th>BPCL</th>\n",
       "      <th>BHARTIARTL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>-0.004504</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.022448</td>\n",
       "      <td>0.048214</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.023222</td>\n",
       "      <td>0.047014</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025121</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>0.053787</td>\n",
       "      <td>0.012877</td>\n",
       "      <td>0.015827</td>\n",
       "      <td>0.038448</td>\n",
       "      <td>-0.016129</td>\n",
       "      <td>0.040168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>-0.032017</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.008843</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009246</td>\n",
       "      <td>-0.025421</td>\n",
       "      <td>-0.019210</td>\n",
       "      <td>0.037699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009746</td>\n",
       "      <td>0.008782</td>\n",
       "      <td>-0.028708</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.012656</td>\n",
       "      <td>-0.046136</td>\n",
       "      <td>-0.012481</td>\n",
       "      <td>-0.041036</td>\n",
       "      <td>-0.004336</td>\n",
       "      <td>-0.034295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>-0.039727</td>\n",
       "      <td>-0.019411</td>\n",
       "      <td>0.012543</td>\n",
       "      <td>-0.018825</td>\n",
       "      <td>-0.014670</td>\n",
       "      <td>-0.006002</td>\n",
       "      <td>-0.008815</td>\n",
       "      <td>-0.001994</td>\n",
       "      <td>-0.008723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007593</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>-0.007890</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>-0.022945</td>\n",
       "      <td>-0.005630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>-0.007799</td>\n",
       "      <td>-0.002654</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>-0.012332</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.006751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020119</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>-0.022172</td>\n",
       "      <td>-0.019698</td>\n",
       "      <td>-0.008069</td>\n",
       "      <td>-0.028087</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.036095</td>\n",
       "      <td>-0.040215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  ADANIENT  BRITANNIA     CIPLA  COALINDIA  DIVISLAB   DRREDDY  \\\n",
       "0  2012-01-02  0.000000   0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "1  2012-01-03 -0.004504   0.002241  0.022448   0.048214  0.002943  0.023222   \n",
       "2  2012-01-04 -0.032017   0.002012  0.008843  -0.001528  0.000000 -0.009246   \n",
       "3  2012-01-05 -0.039727  -0.019411  0.012543  -0.018825 -0.014670 -0.006002   \n",
       "4  2012-01-06  0.005428   0.008305  0.010299  -0.007799 -0.002654  0.011950   \n",
       "\n",
       "   EICHERMOT    GRASIM   HCLTECH  ...     TITAN       UPL  ULTRACEMCO  \\\n",
       "0   0.000000  0.000000  0.000000  ...  0.000000  0.000000    0.000000   \n",
       "1   0.047014  0.015053  0.024390  ...  0.025121  0.031102    0.018761   \n",
       "2  -0.025421 -0.019210  0.037699  ... -0.009746  0.008782   -0.028708   \n",
       "3  -0.008815 -0.001994 -0.008723  ... -0.007593  0.004921    0.007181   \n",
       "4  -0.012332  0.006639  0.006751  ... -0.020119  0.000377    0.000435   \n",
       "\n",
       "      WIPRO  AXISBANK  BAJAJ-AUTO  BAJFINANCE  BAJAJFINSV      BPCL  \\\n",
       "0  0.000000  0.000000    0.000000    0.000000    0.000000  0.000000   \n",
       "1  0.043860  0.053787    0.012877    0.015827    0.038448 -0.016129   \n",
       "2  0.004202  0.012656   -0.046136   -0.012481   -0.041036 -0.004336   \n",
       "3 -0.007890  0.026528    0.030199    0.002891    0.005379 -0.022945   \n",
       "4 -0.022172 -0.019698   -0.008069   -0.028087    0.002972  0.036095   \n",
       "\n",
       "   BHARTIARTL  \n",
       "0    0.000000  \n",
       "1    0.040168  \n",
       "2   -0.034295  \n",
       "3   -0.005630  \n",
       "4   -0.040215  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices = np.array(merged_df.drop(columns = ['Date']))\n",
    "returns = np.zeros_like(prices)\n",
    "for i in range(1,returns.shape[0]):\n",
    "  for j in range(returns.shape[1]):\n",
    "    returns[i][j] = (prices[i][j]-prices[i-1][j])/prices[i-1][j]\n",
    "\n",
    "returns_df = pd.DataFrame(columns = merged_df.drop(columns = 'Date').columns,data = returns)\n",
    "returns_df = pd.concat([merged_df['Date'],returns_df], axis = 1)\n",
    "returns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqfAxfc-9Ywr",
    "outputId": "af035a49-a809-4d8a-d88b-38420f4b3176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3005, 47)\n",
      "(2904, 100, 47)\n",
      "(2904, 47)\n"
     ]
    }
   ],
   "source": [
    "sliding_window = 100\n",
    "print(returns.shape)\n",
    "X = np.array([returns[i:i+sliding_window,:] for i in range(0,returns.shape[0]-sliding_window-1)])\n",
    "Y = np.array([returns[i+sliding_window,:] for i in range(0,returns.shape[0]-sliding_window-1)])\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8dleWmeZpwK",
    "outputId": "a920bfdb-b1c9-4e7b-9f75-43bf1986ed25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no NaN values in X.\n"
     ]
    }
   ],
   "source": [
    "# prompt: check for nan values in X\n",
    "\n",
    "nan_count = np.count_nonzero(np.isnan(X))\n",
    "if nan_count > 0:\n",
    "  print(\"There are\", nan_count, \"NaN values in X.\")\n",
    "else:\n",
    "  print(\"There are no NaN values in X.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ioNWNlyZZ-25",
    "outputId": "a994744b-d1a1-4ccb-c985-fb2c1e1abf1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no NaN values in Y.\n"
     ]
    }
   ],
   "source": [
    "# prompt: check for nan values in Y\n",
    "\n",
    "nan_count = np.count_nonzero(np.isnan(Y))\n",
    "if nan_count > 0:\n",
    "  print(\"There are\", nan_count, \"NaN values in Y.\")\n",
    "else:\n",
    "  print(\"There are no NaN values in Y.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "9crdghrlLACA"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "iqk1pGiDbgu1",
    "outputId": "9ae01a02-d586-4305-8df5-7f62e5ecad86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/291 [00:00<?, ?it/s]100%|██████████| 291/291 [00:06<00:00, 44.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: -0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 44.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/1000], Loss: -0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 53.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/1000], Loss: -0.1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 53.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/1000], Loss: -0.1202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 52.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/1000], Loss: -0.1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 53.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/1000], Loss: -0.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 52.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/1000], Loss: -0.1258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 51.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/1000], Loss: -0.1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 48.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/1000], Loss: -0.1297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 49.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: -0.1283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 53.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/1000], Loss: -0.1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 52.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/1000], Loss: -0.1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 44.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/1000], Loss: -0.1293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 50.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/1000], Loss: -0.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 45.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/1000], Loss: -0.1283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 43.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/1000], Loss: -0.1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 43.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/1000], Loss: -0.1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:07<00:00, 40.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/1000], Loss: -0.1302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 46.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/1000], Loss: -0.1310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 45.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/1000], Loss: -0.1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 46.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/1000], Loss: -0.1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 41.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/1000], Loss: -0.1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 42.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/1000], Loss: -0.1327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 45.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/1000], Loss: -0.1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 46.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/1000], Loss: -0.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 50.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/1000], Loss: -0.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 44.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/1000], Loss: -0.1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 47.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/1000], Loss: -0.1288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 46.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/1000], Loss: -0.1314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 44.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/1000], Loss: -0.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 44.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/1000], Loss: -0.1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 43.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/1000], Loss: -0.1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/1000], Loss: -0.1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 43.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/1000], Loss: -0.1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 42.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/1000], Loss: -0.1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 44.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/1000], Loss: -0.1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 47.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/1000], Loss: -0.1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 47.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/1000], Loss: -0.1328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 46.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/1000], Loss: -0.1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 47.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/1000], Loss: -0.1344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 45.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/1000], Loss: -0.1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:05<00:00, 48.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/1000], Loss: -0.1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 48.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/1000], Loss: -0.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 44.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/1000], Loss: -0.1332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:06<00:00, 43.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/1000], Loss: -0.1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:07<00:00, 41.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/1000], Loss: -0.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 11/291 [00:00<00:06, 41.79it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 99\u001b[0m\n\u001b[0;32m     96\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch_X)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m loss_avg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Accumulate loss\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[63], line 63\u001b[0m, in \u001b[0;36mCustomLoss.forward\u001b[1;34m(self, inputs, output, target)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     62\u001b[0m     mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(inputs[i], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m     cov \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     sharpe_ratio[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdot(output[i],target[i])\u001b[38;5;241m/\u001b[39mtorch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mdot(output[i]\u001b[38;5;241m.\u001b[39mT,torch\u001b[38;5;241m.\u001b[39mmatmul(cov,output[i])))\n\u001b[0;32m     65\u001b[0m  \u001b[38;5;66;03m# Compute mean squared error\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Perform scaling on the input data\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_scaled = scaler.fit_transform(\n",
    "#     X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "\n",
    "# Convert scaled data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "\n",
    "# Move tensors to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X_train = X_train.to(device)\n",
    "Y_train = Y_train.to(device)\n",
    "\n",
    "# Create a Dataset from tensors\n",
    "dataset = TensorDataset(X_train, Y_train)\n",
    "\n",
    "# DataLoader with batch size 32 and shuffle=True\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "class LSTMPortfolioModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMPortfolioModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size,\n",
    "                            num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(\n",
    "            0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(\n",
    "            0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "# Custom loss function for regression (MSE)\n",
    "\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self,inputs, output, target):\n",
    "        # print(inputs.shape,output.shape,target.shape)\n",
    "        sharpe_ratio = torch.zeros(inputs.shape[0])\n",
    "        for i in range(inputs.shape[0]):\n",
    "            mean = torch.mean(inputs[i], axis = 0)\n",
    "            cov = torch.cov(inputs[i].T)\n",
    "            sharpe_ratio[i] = torch.dot(output[i],target[i])/torch.sqrt(torch.dot(output[i].T,torch.matmul(cov,output[i])))\n",
    "         # Compute mean squared error\n",
    "        loss = -torch.mean(sharpe_ratio)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[2]\n",
    "hidden_size = 64\n",
    "num_layers = 8\n",
    "output_size = input_size  # Assuming Y_train is of shape (batch_size, output_size)\n",
    "\n",
    "# Create an instance of the model and move it to the GPU\n",
    "model = LSTMPortfolioModel(input_size, hidden_size,\n",
    "                           num_layers, output_size).to(device)\n",
    "\n",
    "# Define custom loss function\n",
    "criterion = CustomLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "losses = []\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    loss_avg = 0\n",
    "    for batch_X, batch_Y in tqdm(dataloader):\n",
    "        # Move batch data to the GPU\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(batch_X,outputs, batch_Y)\n",
    "        loss_avg += loss.item()  # Accumulate loss\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = loss_avg / len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91897\\AppData\\Local\\Temp\\ipykernel_8868\\129976646.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
      "C:\\Users\\91897\\AppData\\Local\\Temp\\ipykernel_8868\\129976646.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
      "100%|██████████| 291/291 [00:03<00:00, 85.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: -0.1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 88.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Loss: -0.1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 89.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 89.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 94.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Loss: -0.1462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 96.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 93.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 87.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 86.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 95.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:02<00:00, 99.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 87.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 82.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 96.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 93.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 86.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Loss: -0.1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 79.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 88.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:02<00:00, 98.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:02<00:00, 98.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 96.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 95.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 95.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:02<00:00, 97.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Loss: -0.1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:02<00:00, 97.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:02<00:00, 97.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 95.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 94.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Loss: -0.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 93.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 94.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 76.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Loss: -0.1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:04<00:00, 67.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Loss: -0.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Loss: -0.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 80.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 90.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Loss: -0.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 93.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 94.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 87.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 86.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Loss: -0.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 81.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Loss: -0.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 77.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 73.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:04<00:00, 70.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:04<00:00, 62.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:04<00:00, 71.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 79.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 85.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100], Loss: -0.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100], Loss: -0.1462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 93.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 90.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100], Loss: -0.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 84.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100], Loss: -0.1462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 83.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 78.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 83.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 85.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 75.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 74.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 82.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:04<00:00, 71.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 77.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100], Loss: -0.1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 80.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100], Loss: -0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 84.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 90.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Loss: -0.1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 93.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 94.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 89.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 93.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 93.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100], Loss: -0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100], Loss: -0.1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 90.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100], Loss: -0.1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 93.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100], Loss: -0.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100], Loss: -0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 92.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100], Loss: -0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 90.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100], Loss: -0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 84.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: -0.1463\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Perform scaling on the input data\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_scaled = scaler.fit_transform(\n",
    "#     X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "\n",
    "# Convert scaled data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "\n",
    "# Move tensors to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X_train = X_train.to(device)\n",
    "Y_train = Y_train.to(device)\n",
    "\n",
    "# Create a Dataset from tensors\n",
    "dataset = TensorDataset(X_train, Y_train)\n",
    "\n",
    "# DataLoader with batch size 32 and shuffle=True\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "class LSTMPortfolioModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMPortfolioModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size,\n",
    "                            num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(\n",
    "            0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(\n",
    "            0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.softmax(out)  # Apply softmax activation function\n",
    "        return out\n",
    "\n",
    "# Custom loss function for regression (MSE)\n",
    "\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, output, target):\n",
    "        mean = torch.mean(inputs, dim=1)  # Compute mean along each sample\n",
    "        # Compute covariance for each sample\n",
    "        cov = torch.stack([torch.cov(input.T) for input in inputs])\n",
    "        # Dot product of output weights and mean returns\n",
    "        portfolio_returns = torch.bmm(\n",
    "            output.unsqueeze(1), mean.unsqueeze(-1)).squeeze()\n",
    "        portfolio_volatility = torch.sqrt(torch.bmm(torch.bmm(output.unsqueeze(\n",
    "            1), cov), output.unsqueeze(-1)).squeeze())  # Compute portfolio volatility\n",
    "        sharpe_ratio = portfolio_returns / portfolio_volatility\n",
    "        loss = -torch.mean(sharpe_ratio)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[2]\n",
    "hidden_size = 64\n",
    "num_layers = 8\n",
    "# Assuming Y_train is of shape (batch_size, output_size)\n",
    "output_size = input_size\n",
    "\n",
    "# Create an instance of the model and move it to the GPU\n",
    "model = LSTMPortfolioModel(input_size, hidden_size,\n",
    "                           num_layers, output_size).to(device)\n",
    "\n",
    "# Define custom loss function\n",
    "criterion = CustomLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "losses = []\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    loss_avg = 0\n",
    "    for batch_X, batch_Y in tqdm(dataloader):\n",
    "        # Move batch data to the GPU\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(batch_X, outputs, batch_Y)\n",
    "        loss_avg += loss.item()  # Accumulate loss\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = loss_avg / len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91897\\AppData\\Local\\Temp\\ipykernel_8868\\363808415.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
      "C:\\Users\\91897\\AppData\\Local\\Temp\\ipykernel_8868\\363808415.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
      "100%|██████████| 291/291 [00:04<00:00, 64.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: -0.1462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:04<00:00, 72.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200], Loss: -0.1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 79.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200], Loss: -0.1542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 88.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200], Loss: -0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 91.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Loss: -0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 81.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200], Loss: -0.1543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 79.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200], Loss: -0.1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:04<00:00, 66.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200], Loss: -0.1548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 79.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200], Loss: -0.1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 88.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: -0.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:03<00:00, 85.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200], Loss: -0.1544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 72/291 [00:00<00:02, 81.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 118\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 118\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    121\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m loss_avg \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define the custom activation function\n",
    "\n",
    "\n",
    "# def scaled_tanh(x):\n",
    "#     tanh_output = torch.tanh(x)  # Apply tanh activation function\n",
    "#     # Scale the output to have sum of absolute values equal to 1\n",
    "#     scaled_output = tanh_output / \\\n",
    "#         torch.sum(torch.abs(tanh_output), dim=1, keepdim=True)\n",
    "#     return scaled_output\n",
    "\n",
    "# Perform scaling on the input data\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_scaled = scaler.fit_transform(\n",
    "#     X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "\n",
    "\n",
    "# Convert scaled data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "\n",
    "# Move tensors to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X_train = X_train.to(device)\n",
    "Y_train = Y_train.to(device)\n",
    "\n",
    "# Create a Dataset from tensors\n",
    "dataset = TensorDataset(X_train, Y_train)\n",
    "\n",
    "# DataLoader with batch size 32 and shuffle=True\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "class LSTMPortfolioModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMPortfolioModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size,\n",
    "                            num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(\n",
    "            0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(\n",
    "            0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Custom loss function for regression (MSE)\n",
    "\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, output, target):\n",
    "        mean = torch.mean(inputs, dim=1)  # Compute mean along each sample\n",
    "        # Compute covariance for each sample\n",
    "        cov = torch.stack([torch.cov(input.T) for input in inputs])\n",
    "        # Dot product of output weights and mean returns\n",
    "        portfolio_returns = torch.bmm(\n",
    "            output.unsqueeze(1), mean.unsqueeze(-1)).squeeze()\n",
    "        portfolio_volatility = torch.sqrt(torch.bmm(torch.bmm(output.unsqueeze(\n",
    "            1), cov), output.unsqueeze(-1)).squeeze())  # Compute portfolio volatility\n",
    "        sharpe_ratio = portfolio_returns / portfolio_volatility\n",
    "        loss = -torch.mean(sharpe_ratio)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[2]\n",
    "hidden_size = 64\n",
    "num_layers = 8\n",
    "# Assuming Y_train is of shape (batch_size, output_size)\n",
    "output_size = input_size\n",
    "\n",
    "# Create an instance of the model and move it to the GPU\n",
    "model = LSTMPortfolioModel(input_size, hidden_size,\n",
    "                           num_layers, output_size).to(device)\n",
    "\n",
    "# Define custom loss function\n",
    "criterion = CustomLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "losses = []\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    loss_avg = 0\n",
    "    for batch_X, batch_Y in tqdm(dataloader):\n",
    "        # Move batch data to the GPU\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        # Apply the custom activation function\n",
    "        outputs = scaled_tanh(outputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(batch_X, outputs, batch_Y)\n",
    "        loss_avg += loss.item()  # Accumulate loss\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = loss_avg / len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5yx6MqRkvXN"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyPUaAhVavT9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.isnan(Y_train[2026]).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TI585V3S4YST"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[0;32m      4\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m----> 5\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:450\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:490\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    487\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    489\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 490\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m data_min \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    498\u001b[0m data_max \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\91897\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\_tensor.py:1032\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyfolio\n",
      "  Using cached pyfolio-0.9.2-py3-none-any.whl\n",
      "Requirement already satisfied: seaborn>=0.7.1 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from pyfolio) (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from pyfolio) (1.22.4)\n",
      "Requirement already satisfied: pytz>=2014.10 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from pyfolio) (2023.3.post1)\n",
      "Requirement already satisfied: ipython>=3.2.3 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from pyfolio) (8.2.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from pyfolio) (3.5.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from pyfolio) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.16.1 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from pyfolio) (1.0.2)\n",
      "Requirement already satisfied: pandas>=0.18.1 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from pyfolio) (1.4.2)\n",
      "Collecting empyrical>=0.5.0\n",
      "  Using cached empyrical-0.5.5-py3-none-any.whl\n",
      "Collecting pandas-datareader>=0.2\n",
      "  Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
      "     ------------------------------------ 109.5/109.5 kB 902.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\91897\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio) (0.4.4)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio) (2.15.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\91897\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\91897\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio) (0.1.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio) (68.1.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio) (3.0.20)\n",
      "Requirement already satisfied: decorator in c:\\users\\91897\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio) (0.18.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\91897\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio) (0.2.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\91897\\anaconda3\\lib\\site-packages (from ipython>=3.2.3->pyfolio) (0.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->pyfolio) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->pyfolio) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->pyfolio) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->pyfolio) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->pyfolio) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->pyfolio) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->pyfolio) (9.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from scikit-learn>=0.16.1->pyfolio) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from scikit-learn>=0.16.1->pyfolio) (2.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio) (0.8.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.31.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\91897\\anaconda3\\lib\\site-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (4.9.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\91897\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=3.2.3->pyfolio) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->pyfolio) (1.16.0)\n",
      "Requirement already satisfied: executing in c:\\users\\91897\\anaconda3\\lib\\site-packages (from stack-data->ipython>=3.2.3->pyfolio) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\91897\\anaconda3\\lib\\site-packages (from stack-data->ipython>=3.2.3->pyfolio) (0.2.2)\n",
      "Requirement already satisfied: asttokens in c:\\users\\91897\\anaconda3\\lib\\site-packages (from stack-data->ipython>=3.2.3->pyfolio) (2.0.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91897\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.0.4)\n",
      "Installing collected packages: pandas-datareader, empyrical, pyfolio\n",
      "Successfully installed empyrical-0.5.5 pandas-datareader-0.10.0 pyfolio-0.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.000000\n",
       "1   -0.004504\n",
       "2   -0.032017\n",
       "3   -0.039727\n",
       "4    0.005428\n",
       "Name: ADANIENT, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df['ADANIENT'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "XtuJa5iN6ETZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91897\\anaconda3\\lib\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'strftime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyfolio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m----> 3\u001b[0m \u001b[43mpf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_simple_tear_sheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturns_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mADANIENT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyfolio\\plotting.py:52\u001b[0m, in \u001b[0;36mcustomize.<locals>.call_w_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m set_context:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m plotting_context(), axes_style():\n\u001b[1;32m---> 52\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyfolio\\tears.py:359\u001b[0m, in \u001b[0;36mcreate_simple_tear_sheet\u001b[1;34m(returns, positions, transactions, benchmark_rets, slippage, estimate_intraday, live_start_date, turnover_denom, header_rows)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m live_start_date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     live_start_date \u001b[38;5;241m=\u001b[39m ep\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mget_utc_timestamp(live_start_date)\n\u001b[1;32m--> 359\u001b[0m \u001b[43mplotting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_perf_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mbenchmark_rets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtransactions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mturnover_denom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mturnover_denom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mlive_start_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlive_start_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mheader_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader_rows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, vertical_sections \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m    368\u001b[0m gs \u001b[38;5;241m=\u001b[39m gridspec\u001b[38;5;241m.\u001b[39mGridSpec(vertical_sections, \u001b[38;5;241m3\u001b[39m, wspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, hspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyfolio\\plotting.py:595\u001b[0m, in \u001b[0;36mshow_perf_stats\u001b[1;34m(returns, factor_returns, positions, transactions, turnover_denom, live_start_date, bootstrap, header_rows)\u001b[0m\n\u001b[0;32m    593\u001b[0m date_rows \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(returns\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 595\u001b[0m     date_rows[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mreturns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    596\u001b[0m     date_rows[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnd date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m returns\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m live_start_date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'strftime'"
     ]
    }
   ],
   "source": [
    "import pyfolio as pf\n",
    "from datetime import datetime\n",
    "pf.create_simple_tear_sheet(pd.Series(returns_df['ADANIENT']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_simple_tear_sheet in module pyfolio.tears:\n",
      "\n",
      "create_simple_tear_sheet(returns, positions=None, transactions=None, benchmark_rets=None, slippage=None, estimate_intraday='infer', live_start_date=None, turnover_denom='AGB', header_rows=None)\n",
      "    Simpler version of create_full_tear_sheet; generates summary performance\n",
      "    statistics and important plots as a single image.\n",
      "    \n",
      "    - Plots: cumulative returns, rolling beta, rolling Sharpe, underwater,\n",
      "        exposure, top 10 holdings, total holdings, long/short holdings,\n",
      "        daily turnover, transaction time distribution.\n",
      "    - Never accept market_data input (market_data = None)\n",
      "    - Never accept sector_mappings input (sector_mappings = None)\n",
      "    - Never perform bootstrap analysis (bootstrap = False)\n",
      "    - Never hide posistions on top 10 holdings plot (hide_positions = False)\n",
      "    - Always use default cone_std (cone_std = (1.0, 1.5, 2.0))\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    returns : pd.Series\n",
      "        Daily returns of the strategy, noncumulative.\n",
      "         - Time series with decimal returns.\n",
      "         - Example:\n",
      "            2015-07-16    -0.012143\n",
      "            2015-07-17    0.045350\n",
      "            2015-07-20    0.030957\n",
      "            2015-07-21    0.004902\n",
      "    positions : pd.DataFrame, optional\n",
      "        Daily net position values.\n",
      "         - Time series of dollar amount invested in each position and cash.\n",
      "         - Days where stocks are not held can be represented by 0 or NaN.\n",
      "         - Non-working capital is labelled 'cash'\n",
      "         - Example:\n",
      "            index         'AAPL'         'MSFT'          cash\n",
      "            2004-01-09    13939.3800     -14012.9930     711.5585\n",
      "            2004-01-12    14492.6300     -14624.8700     27.1821\n",
      "            2004-01-13    -13853.2800    13653.6400      -43.6375\n",
      "    transactions : pd.DataFrame, optional\n",
      "        Executed trade volumes and fill prices.\n",
      "        - One row per trade.\n",
      "        - Trades on different names that occur at the\n",
      "          same time will have identical indicies.\n",
      "        - Example:\n",
      "            index                  amount   price    symbol\n",
      "            2004-01-09 12:18:01    483      324.12   'AAPL'\n",
      "            2004-01-09 12:18:01    122      83.10    'MSFT'\n",
      "            2004-01-13 14:12:23    -75      340.43   'AAPL'\n",
      "    benchmark_rets : pd.Series, optional\n",
      "        Daily returns of the benchmark, noncumulative.\n",
      "    slippage : int/float, optional\n",
      "        Basis points of slippage to apply to returns before generating\n",
      "        tearsheet stats and plots.\n",
      "        If a value is provided, slippage parameter sweep\n",
      "        plots will be generated from the unadjusted returns.\n",
      "        Transactions and positions must also be passed.\n",
      "        - See txn.adjust_returns_for_slippage for more details.\n",
      "    live_start_date : datetime, optional\n",
      "        The point in time when the strategy began live trading,\n",
      "        after its backtest period. This datetime should be normalized.\n",
      "    turnover_denom : str, optional\n",
      "        Either AGB or portfolio_value, default AGB.\n",
      "        - See full explanation in txn.get_turnover.\n",
      "    header_rows : dict or OrderedDict, optional\n",
      "        Extra rows to display at the top of the perf stats table.\n",
      "    set_context : boolean, optional\n",
      "        If True, set default plotting style context.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pf.create_simple_tear_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
