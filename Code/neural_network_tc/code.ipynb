{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming Approach for Single asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10901082]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, [-0.02637119549933424, 0.000308]],\n",
       " [0, [-0.003925489439034004, 0.000308]],\n",
       " [0, [0.001433060220007208, 0.000308]],\n",
       " [0, [-0.0003021229777282262, 0.000308]],\n",
       " [1, [0.06195451295958909, 0.000308]],\n",
       " [0, [0.01958357405144355, 0.000308]],\n",
       " [1, [-0.030584493046751444, 0.000308]],\n",
       " [0, [-0.0035973842553287242, 0.000308]],\n",
       " [1, [-0.024172612483892093, 0.000308]],\n",
       " [0, [-0.00612667760598358, 0.000308]],\n",
       " [1, [-0.01340361822068544, 0.000308]],\n",
       " [0, [0.005699398015680224, 0.000308]],\n",
       " [0, [0.02885188680123323, 0.000308]],\n",
       " [1, [0.013808115115656758, 0.000308]],\n",
       " [1, [0.02020936999199747, 0.000308]],\n",
       " [1, [-0.039285383742190254, 0.000308]],\n",
       " [0, [0.010816333403151503, 0.000308]],\n",
       " [1, [-0.020625283799474405, 0.000308]],\n",
       " [0, [-0.013292467264263282, 0.000308]],\n",
       " [0, [-0.008014220641217885, 0.000308]],\n",
       " [1, [-0.0396577298359725, 0.000308]],\n",
       " [1, [0.025128735245069367, 0.000308]],\n",
       " [0, [0.0013258749627051165, 0.000308]],\n",
       " [1, [0.011875506519307473, 0.000308]],\n",
       " [1, [0.028412642804753325, 0.000308]],\n",
       " [0, [0.021154852608786103, 0.000308]],\n",
       " [1, [-0.0042832220692907335, 0.000308]],\n",
       " [0, [-0.015279075073793459, 0.000308]],\n",
       " [0, [-0.019884428924912035, 0.000308]],\n",
       " [1, [0.012945871549454632, 0.000308]],\n",
       " [0, [-0.01644996370725133, 0.000308]],\n",
       " [1, [-0.06031941952911568, 0.000308]],\n",
       " [1, [-0.005984019260478045, 0.000308]],\n",
       " [0, [0.014366086637692378, 0.000308]],\n",
       " [0, [-0.017821114222116196, 0.000308]],\n",
       " [1, [-0.010470559513530554, 0.000308]],\n",
       " [1, [0.02682736462032817, 0.000308]],\n",
       " [0, [-0.011883947053989813, 0.000308]],\n",
       " [1, [-0.06462116218406729, 0.000308]],\n",
       " [1, [-0.04158276253452313, 0.000308]],\n",
       " [1, [0.021300705504021043, 0.000308]],\n",
       " [0, [0.029610540723453826, 0.000308]],\n",
       " [0, [-0.011638952952756866, 0.000308]],\n",
       " [0, [0.02133770920119964, 0.000308]],\n",
       " [1, [0.01037391205414082, 0.000308]],\n",
       " [0, [-0.02918639917147133, 0.000308]],\n",
       " [0, [0.007402171231808403, 0.000308]],\n",
       " [0, [0.025451253813243705, 0.000308]],\n",
       " [0, [0.012815934294529522, 0.000308]],\n",
       " [0, [-0.00827062729740022, 0.000308]]]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "def generate_normal_distribution(n):\n",
    "\n",
    "    L = np.random.rand(n, n)\n",
    "    cov_matrix = np.dot(L, L.T)\n",
    "\n",
    "    mean = np.random.randn(n)\n",
    "    print(mean)\n",
    "    \n",
    "    return [mean,cov_matrix]\n",
    "\n",
    "#generate_normal_distribution(5)\n",
    "\n",
    "\n",
    "R0 = np.random.randn(1)\n",
    "print(R0)\n",
    "def get_riskfree_price(t):\n",
    "    return R0*np.exp(rf*t)\n",
    "\n",
    "n = 1\n",
    "regimes = []\n",
    "N = 2\n",
    "T= 50\n",
    "rf = 0.0154/50\n",
    "gamma = -1\n",
    "tpm = np.array([[0.981,0.019],[0.047,0.953]])\n",
    "#transaction_rate = 0.1\n",
    "# for i in range(N):\n",
    "#     regimes.append(generate_normal_distribution(n))\n",
    "\n",
    "regimes = [[[0.00312],[[0.00022]]],[[-0.00175],[[0.00116]]]]\n",
    "\n",
    "def generate_scenario(prob,t):\n",
    "    # curren\n",
    "    # returns_for_regimes = []\n",
    "    # for i in range(N):\n",
    "    #     sample = np.random.multivariate_normal(mean = regimes[i][0], cov= regimes[i][1])\n",
    "    #     returns_for_regimes.append(sample)\n",
    "\n",
    "    # returns_for_regimes = np.array(returns_for_regimes)\n",
    "\n",
    "    # sample = []\n",
    "    # for i in range(n):\n",
    "    #     value = 0\n",
    "    #     for j in range(N):\n",
    "    #         value+= prob[j]*returns_for_regimes[j][i]\n",
    "    #     sample.append(value)\n",
    "    # sample.append(get_riskfree_price(t)[0])\n",
    "    current_regime = np.random.choice(N,p = prob)\n",
    "    #print(current_regime)\n",
    "    sample = list(np.random.multivariate_normal(mean = regimes[current_regime][0], cov= regimes[current_regime][1]))\n",
    "    #sample.append(get_riskfree_price(t)[0])\n",
    "    sample.append(rf)\n",
    "    return np.array(sample)\n",
    "\n",
    "def generate_monte_carlo_sample():\n",
    "    sample = []\n",
    "    curr_prob = np.random.rand(N)\n",
    "    curr_prob/=np.sum(curr_prob)\n",
    "    curr_regime = np.random.choice(range(N), p = curr_prob)\n",
    "    #print(regimes[curr_regime][1])\n",
    "    returns = list(np.random.multivariate_normal(mean = regimes[curr_regime][0], cov= regimes[curr_regime][1]))\n",
    "    returns.append(rf)\n",
    "    sample.append([curr_regime,returns])\n",
    "    for i in range(T-1):\n",
    "        curr_prob = tpm @ curr_prob\n",
    "        curr_prob/=np.sum(curr_prob)\n",
    "        curr_regime = np.random.choice(range(N), p = curr_prob)\n",
    "        returns = list(np.random.multivariate_normal(mean = regimes[curr_regime][0], cov= regimes[curr_regime][1]))\n",
    "        returns.append(rf)\n",
    "        sample.append([curr_regime,returns])\n",
    "    \n",
    "    return sample\n",
    "\n",
    "\n",
    "generate_monte_carlo_sample()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#generate_scenario([0.1,0.1,0.3,0.2,0.3],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00175], [[0.00116]]]\n"
     ]
    }
   ],
   "source": [
    "print(regimes[1][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilty set initialization over different regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from scipy.optimize import minimize\n",
    "discrete_prob = 10\n",
    "prob_set = []\n",
    "for i in range(discrete_prob+1):\n",
    "    prob_set.append(1/(discrete_prob)*i)\n",
    "\n",
    "combinations = product(prob_set, repeat=N)\n",
    "possible_probabities = [vector for vector in combinations if sum(vector) == 1]\n",
    "reverse_index = {}\n",
    "for _,p in enumerate(possible_probabities):\n",
    "    reverse_index[p]= _\n",
    "\n",
    "possible_probabities = [np.array(x) for x in possible_probabities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_pi = 0.1\n",
    "pi_set = []\n",
    "curr_pi = -1\n",
    "while curr_pi<=1+1e-5:\n",
    "    pi_set.append(curr_pi)\n",
    "    curr_pi+=delta_pi\n",
    "\n",
    "pi_combinations = product(pi_set,repeat=n)\n",
    "possible_pi = [np.append(np.array(vector),1-np.sum(vector)) for vector in pi_combinations]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 2.22044605e-16]\n"
     ]
    }
   ],
   "source": [
    "print(possible_pi[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_probability_distn(p_in):\n",
    "    lowest_norm = float('inf')  # Set to positive infinity initially\n",
    "    ind = 0\n",
    "    #p_in = p_in.detach().numpy()\n",
    "    # Iterate through the set and calculate the norm for each element\n",
    "    for _,array in enumerate(possible_probabities):\n",
    "        norm = np.linalg.norm(p_in - array)  # Calculate the Euclidean norm\n",
    "        if norm < lowest_norm:\n",
    "            lowest_norm = norm\n",
    "            closest_array = array\n",
    "            ind = _\n",
    "\n",
    "    return ind,closest_array\n",
    "\n",
    "def updateBelief(r,p):\n",
    "    #print(r,p)\n",
    "    p_new = []\n",
    "    #print(r)\n",
    "    r = r[:-1]\n",
    "    density = np.zeros(N);\n",
    "    for i in range(N):\n",
    "        mvn = multivariate_normal(mean=regimes[i][0], cov = regimes[i][1])\n",
    "        density[i]= mvn.pdf(r)\n",
    "\n",
    "    p_new = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            p_new[i]+= density[j]*tpm[j][i]*p[j]\n",
    "\n",
    "    p_new/=np.sum(p_new)\n",
    "    closest_p_ind,_ = closest_probability_distn(p_new)\n",
    "    return p_new,closest_p_ind\n",
    "\n",
    "def newWealth(r, pi):\n",
    "    W_new = 0\n",
    "    for i in range(n+1):\n",
    "        W_new+= pi[i]*(1+r[i])\n",
    "    return W_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4 [0. 1.] [-1  2]\n",
      "0 4 [0.1 0.9] [-0.7  1.7]\n",
      "0 4 [0.2 0.8] [-1  2]\n",
      "0 4 [0.3 0.7] [0.7 0.3]\n",
      "0 4 [0.4 0.6] [-0.2  1.2]\n",
      "0 4 [0.5 0.5] [-0.1  1.1]\n",
      "0 4 [0.6 0.4] [-1.38777878e-16  1.00000000e+00]\n",
      "0 4 [0.7 0.3] [1.00000000e+00 2.22044605e-16]\n",
      "0 4 [0.8 0.2] [1.00000000e+00 2.22044605e-16]\n",
      "0 4 [0.9 0.1] [1.00000000e+00 2.22044605e-16]\n",
      "0 4 [1. 0.] [1.00000000e+00 2.22044605e-16]\n",
      "\n",
      "\n",
      "0 3 [0. 1.] [-0.5  1.5]\n",
      "0 3 [0.1 0.9] [-0.9  1.9]\n",
      "0 3 [0.2 0.8] [-0.5  1.5]\n",
      "0 3 [0.3 0.7] [0.4 0.6]\n",
      "0 3 [0.4 0.6] [-0.2  1.2]\n",
      "0 3 [0.5 0.5] [-1  2]\n",
      "0 3 [0.6 0.4] [1.00000000e+00 2.22044605e-16]\n",
      "0 3 [0.7 0.3] [0.8 0.2]\n",
      "0 3 [0.8 0.2] [1.00000000e+00 2.22044605e-16]\n",
      "0 3 [0.9 0.1] [1.00000000e+00 2.22044605e-16]\n",
      "0 3 [1. 0.] [1.00000000e+00 2.22044605e-16]\n",
      "\n",
      "\n",
      "0 2 [0. 1.] [-0.5  1.5]\n",
      "0 2 [0.1 0.9] [0.4 0.6]\n",
      "0 2 [0.2 0.8] [-0.9  1.9]\n",
      "0 2 [0.3 0.7] [-1  2]\n",
      "0 2 [0.4 0.6] [-0.4  1.4]\n",
      "0 2 [0.5 0.5] [-0.5  1.5]\n",
      "0 2 [0.6 0.4] [-0.7  1.7]\n",
      "0 2 [0.7 0.3] [1.00000000e+00 2.22044605e-16]\n",
      "0 2 [0.8 0.2] [1.00000000e+00 2.22044605e-16]\n",
      "0 2 [0.9 0.1] [1.00000000e+00 2.22044605e-16]\n",
      "0 2 [1. 0.] [1.00000000e+00 2.22044605e-16]\n",
      "\n",
      "\n",
      "0 1 [0. 1.] [-1  2]\n",
      "0 1 [0.1 0.9] [-0.2  1.2]\n",
      "0 1 [0.2 0.8] [-1.38777878e-16  1.00000000e+00]\n",
      "0 1 [0.3 0.7] [1.00000000e+00 2.22044605e-16]\n",
      "0 1 [0.4 0.6] [1.00000000e+00 2.22044605e-16]\n",
      "0 1 [0.5 0.5] [0.4 0.6]\n",
      "0 1 [0.6 0.4] [0.6 0.4]\n",
      "0 1 [0.7 0.3] [1.00000000e+00 2.22044605e-16]\n",
      "0 1 [0.8 0.2] [0.3 0.7]\n",
      "0 1 [0.9 0.1] [1.00000000e+00 2.22044605e-16]\n",
      "0 1 [1. 0.] [1.00000000e+00 2.22044605e-16]\n",
      "\n",
      "\n",
      "0 0 [0. 1.] [0.3 0.7]\n",
      "0 0 [0.1 0.9] [-1  2]\n",
      "0 0 [0.2 0.8] [-1  2]\n",
      "0 0 [0.3 0.7] [-0.5  1.5]\n",
      "0 0 [0.4 0.6] [-0.2  1.2]\n",
      "0 0 [0.5 0.5] [1.00000000e+00 2.22044605e-16]\n",
      "0 0 [0.6 0.4] [1.00000000e+00 2.22044605e-16]\n",
      "0 0 [0.7 0.3] [0.2 0.8]\n",
      "0 0 [0.8 0.2] [1.00000000e+00 2.22044605e-16]\n",
      "0 0 [0.9 0.1] [1.00000000e+00 2.22044605e-16]\n",
      "0 0 [1. 0.] [1.00000000e+00 2.22044605e-16]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "V = {}\n",
    "for _ in range(len(possible_probabities)):\n",
    "    V[(_,T)] = (1**gamma)/gamma\n",
    "\n",
    "t = T-1\n",
    "M = 200\n",
    "pi_l = -1.0\n",
    "pi_u = 1.0\n",
    "\n",
    "   \n",
    "optimal_pi_star = {}\n",
    "\n",
    "# scenarios = []_star = {}\n",
    "for iter in range(1):\n",
    "    # scenarios = []\n",
    "    # for j in range(M):\n",
    "    #     sample = generate_monte_carlo_sample()\n",
    "    #     scenarios.append(sample)\n",
    "    # print(scenarios)\n",
    "    t = T-1\n",
    "    while (t>=0):\n",
    "        # returns_at_this_time = [scenarios[i][t][1] for i in range(M)]\n",
    "        # print(returns_at_this_time)\n",
    "        for _ in range(len(possible_probabities)):\n",
    "            returns_at_this_time = []\n",
    "            for j in range(M):\n",
    "                sample = generate_scenario(possible_probabities[_],t)\n",
    "                returns_at_this_time.append(sample)\n",
    "            def objective_function(pi):\n",
    "                return np.average([(newWealth(returns_at_this_time[i],pi)**gamma)*V[(updateBelief(returns_at_this_time[i],possible_probabities[_])[1],t+1)] for i in range(M)])\n",
    "\n",
    "            constraints = ([{'type': 'eq', 'fun': lambda pi: np.sum(pi) - 1}])  # Example constraint: pi sums to 1\n",
    "\n",
    "            #Initial guess for pi (dimension n)\n",
    "            # initial_pi_guess = np.ones(n+1) \n",
    "            # initial_pi_guess/=np.sum(initial_pi_guess)# Starting with equal weights\n",
    "\n",
    "            # #Minimize the negative of the objective function to maximize\n",
    "            # pi_star = minimize(lambda x: (-1)*objective_function(x),  initial_pi_guess,\n",
    "            #                    constraints=constraints,\n",
    "            #                     bounds = [(pi_l,pi_u) for i in range(n)] + [(None,None)]\n",
    "            #                     )\n",
    "\n",
    "            pi_star = max(possible_pi,key = objective_function)\n",
    "            # print(pi_star.message)\n",
    "            # pi_star = pi_star.x\n",
    "            # for i in range(n+1):\n",
    "            #     pi_star[i] = max(pi_l,min(pi_u,pi_star[i]))\n",
    "            V[(_,t)] = np.average([(newWealth(returns_at_this_time[i],pi_star)**gamma)*V[(updateBelief(returns_at_this_time[i],possible_probabities[_])[1],t+1)] for i in range(M)])\n",
    "            optimal_pi_star[(_,t)] = pi_star\n",
    "            print(iter,t,possible_probabities[_],pi_star)\n",
    "\n",
    "        t= t-1\n",
    "        print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.3, 0.7]), array([-1,  2]), array([-1,  2]), array([-0.5,  1.5]), array([-0.2,  1.2])]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xpoints = [x[0] for x in possible_probabities]\n",
    "ypoints = [optimal_pi_star[_,4][0] for _ in range(len(possible_probabities))]\n",
    "\n",
    "plt.plot(xpoints,ypoints)\n",
    "plt.show()\n",
    "\n",
    "print([optimal_pi_star[_,0] for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "-0.9948425281848563\n",
      "[0.02 0.98]\n",
      "-0.9954187341391277\n",
      "[0.04 0.96]\n",
      "-0.9936693202103825\n",
      "[0.06 0.94]\n",
      "-0.993258559195663\n",
      "[0.08 0.92]\n",
      "-0.9956728746280783\n",
      "[0.1 0.9]\n",
      "-0.9949216142604204\n",
      "[0.12 0.88]\n",
      "-0.9956795704411443\n",
      "[0.14 0.86]\n",
      "-0.9953472068804257\n",
      "[0.16 0.84]\n",
      "-0.9952948148439712\n",
      "[0.18 0.82]\n",
      "-0.9960670864163788\n",
      "[0.2 0.8]\n",
      "-0.9951257883536586\n",
      "[0.22 0.78]\n",
      "-0.9957399363347562\n",
      "[0.24 0.76]\n",
      "-0.994940870256214\n",
      "[0.26 0.74]\n",
      "-0.9951479844356311\n",
      "[0.28 0.72]\n",
      "-0.995584034805725\n",
      "[0.3 0.7]\n",
      "-0.9955870860715633\n",
      "[0.32 0.68]\n",
      "-0.9959215933066633\n",
      "[0.34 0.66]\n",
      "-0.9958207307194427\n",
      "[0.36 0.64]\n",
      "-0.9953794189633677\n",
      "[0.38 0.62]\n",
      "-0.9959068760439989\n",
      "[0.4 0.6]\n",
      "-0.9956560043730692\n",
      "[0.42 0.58]\n",
      "-0.9951605747336234\n",
      "[0.44 0.56]\n",
      "-0.994749418915084\n",
      "[0.46 0.54]\n",
      "-0.9950926274636861\n",
      "[0.48 0.52]\n",
      "-0.9950210010373791\n",
      "[0.5 0.5]\n",
      "-0.9940251364600347\n",
      "[0.52 0.48]\n",
      "-0.9943786368043029\n",
      "[0.54 0.46]\n",
      "-0.995131073674532\n",
      "[0.56 0.44]\n",
      "-0.9939270025692986\n",
      "[0.58 0.42]\n",
      "-0.9937538348009185\n",
      "[0.6 0.4]\n",
      "-0.9934857495776473\n",
      "[0.62 0.38]\n",
      "-0.9931855064261159\n",
      "[0.64 0.36]\n",
      "-0.9921536270166327\n",
      "[0.66 0.34]\n",
      "-0.9931415209371012\n",
      "[0.68 0.32]\n",
      "-0.9929802654795026\n",
      "[0.7 0.3]\n",
      "-0.9930408756207557\n",
      "[0.72 0.28]\n",
      "-0.9931994979766267\n",
      "[0.74 0.26]\n",
      "-0.9926227741573486\n",
      "[0.76 0.24]\n",
      "-0.9914499238123449\n",
      "[0.78 0.22]\n",
      "-0.9921071374804156\n",
      "[0.8 0.2]\n",
      "-0.9906669704624399\n",
      "[0.82 0.18]\n",
      "-0.9906804497848813\n",
      "[0.84 0.16]\n",
      "-0.989536007619138\n",
      "[0.86 0.14]\n",
      "-0.9895090117914243\n",
      "[0.88 0.12]\n",
      "-0.9901741944679484\n",
      "[0.9 0.1]\n",
      "-0.9893195121597905\n",
      "[0.92 0.08]\n",
      "-0.9882205250550933\n",
      "[0.94 0.06]\n",
      "-0.9878280201202734\n",
      "[0.96 0.04]\n",
      "-0.987825646080709\n",
      "[0.98 0.02]\n",
      "-0.9880749382529296\n",
      "[1. 0.]\n",
      "-0.9872380211374601\n"
     ]
    }
   ],
   "source": [
    "for _ in range(len(possible_probabities)):\n",
    "    print(possible_probabities[_])\n",
    "    print(V[(_,0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network using Dynamic Program solution as a startpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# transaction_rate = 0.005\n",
    "\n",
    "# def newWealth_withTC(W,r,pi_pre,pi_new):\n",
    "#     # W_new = torch.scalar_tensor(0,requires_grad=True)\n",
    "#     # #W_new = 0\n",
    "#     # #W = torch.scalar_tensor(W,requires_grad=True)\n",
    "#     # r = torch.tensor(r,requires_grad=True)\n",
    "#     # for i in range(n+1):\n",
    "#     #     W_new += W*pi_pre[i]*(1+r[i])\n",
    "#     # W_new = W_new - W_new*transaction_rate*torch.norm(pi_new-pi_pre,p = 1)\n",
    "#     # return torch.tensor(W_new,requires_grad=True)\n",
    "#     W = torch.tensor(W, requires_grad=True)\n",
    "#     r = torch.tensor(r, requires_grad=True)\n",
    "#     pi_pre = torch.tensor(pi_pre, requires_grad=True)\n",
    "#     pi_new = torch.tensor(pi_new, requires_grad=True)\n",
    "\n",
    "#     n = len(r) - 1\n",
    "#     W_new = torch.scalar_tensor(0.0, requires_grad=True)\n",
    "\n",
    "#     # Accumulate values in a new tensor without in-place operations\n",
    "#     for i in range(n + 1):\n",
    "#         W_new = W_new + W * pi_pre[i] * (1 + r[i])\n",
    "\n",
    "#     tc = transaction_rate * torch.norm(pi_new - pi_pre, p=1)\n",
    "\n",
    "#     # Update W_new with the transaction cost\n",
    "#     W_new = W_new - W_new * tc\n",
    "\n",
    "#     return W_new\n",
    "\n",
    "\n",
    "# class CustomLoss(nn.Module):\n",
    "#     def __init__(self, crra_coefficient):\n",
    "#         super(CustomLoss, self).__init__()\n",
    "#         self.crra_coefficient = crra_coefficient\n",
    "\n",
    "#     def forward(self, initial_wealth, initial_portfolio, upper_b, lower_b,returns,input_data):\n",
    "#         # Calculate the CRRA utility loss\n",
    "#         input_size = upper_b.shape[0]\n",
    "#         total_loss = 0\n",
    "#         #print(lower_b.shape,upper_b.shape)\n",
    "#         for _ in range(input_size):\n",
    "#             wealth = [initial_wealth]\n",
    "#             portfolio = [initial_portfolio]\n",
    "#             pi_star_arrays = []\n",
    "#             #print(portfolio)\n",
    "#             #constraint_loss = 0\n",
    "#             for i in range(T):\n",
    "#                 w = wealth[-1]\n",
    "#                 pi = portfolio[-1]\n",
    "#                 pi_new = pi.clone().detach()\n",
    "#                 pi_new = pi_new[:-1]\n",
    "\n",
    "#                 closest_p_ind,__ = closest_probability_distn(input_data[_][i])\n",
    "#                 pi_star = torch.tensor(optimal_pi_star[(closest_p_ind,i)],requires_grad=True)\n",
    "#                 pi_star_arrays.append(pi_star)\n",
    "#                 pi_star = pi_star[:-1]\n",
    "#                 #print(\"Pi star: \",pi_star)\n",
    "#                 #print(lb,ub)\n",
    "#                 # print(\"Pi_star :\",pi_star)\n",
    "#                 u_b = upper_b[_][i]\n",
    "#                 l_b = lower_b[_][i]\n",
    "\n",
    "#                 #print(\"Boundaries: \",l_b,u_b)\n",
    "#                 #constraint_loss+= torch.sum(torch.relu(l_b - u_b))*1000\n",
    "#                 #print(constraint_loss)\n",
    "#                 # print(\"Pi: \",pi_new)\n",
    "#                 # print(\"Upper_delta: \",u_b)\n",
    "#                 # print(\"Lower delta: \",l_b)\n",
    "#                 # for j in range(n):\n",
    "#                 #     pi_new[j] = max(max(-1.0,l_b[j]), min(min(u_b[j],1), pi_new[j]))\n",
    "#                 u_b = torch.min(torch.ones(n),torch.add(pi_star,u_b))\n",
    "#                 l_b = torch.max(-torch.ones(n),torch.add(pi_star,-l_b))\n",
    "#                 pi_new = torch.max(l_b,torch.min(u_b,pi_new))\n",
    "#                 # print(\"Upper boundary: \",u_b)\n",
    "#                 # print(\"Lower_boundary: \",l_b)\n",
    "#                 # print(\"Pi: \",pi_new)\n",
    "#                 risk_free_allocation = torch.tensor([1-torch.sum(pi_new)],requires_grad=True)\n",
    "#                 #print(risk_free_allocation)\n",
    "#                 #print(risk_free_allocation)\n",
    "#                 pi_new = torch.stack((pi_new,risk_free_allocation)).reshape(n+1)\n",
    "#                 #print(pi_new)\n",
    "#                 portfolio.append(torch.tensor(pi_new,requires_grad=True))\n",
    "#                 #print(portfolio)\n",
    "#                 new_wealth = newWealth_withTC(W=w,r = returns[_][i], pi_pre= pi,pi_new= pi_new)\n",
    "#                 #print(new_wealth)\n",
    "#                 wealth.append(new_wealth)\n",
    "\n",
    "#             #print(wealth)\n",
    "#             loss = -((wealth[-1]) ** self.crra_coefficient) / self.crra_coefficient \n",
    "\n",
    "#             total_loss+= loss\n",
    "#             # print(\"Portfolio: \",portfolio)\n",
    "#             # print(\"Wealth: \",wealth)\n",
    "#             # print(\"Optimal_portfolios: \",pi_star_arrays)\n",
    "        \n",
    "#         return total_loss/input_size\n",
    "\n",
    "# # Define your RNN cell with two neural networks\n",
    "# class CustomRNNCell(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super(CustomRNNCell, self).__init__()\n",
    "#         self.input_size = input_size\n",
    "#         #self.hidden_size = hidden_size\n",
    "#         self.output_size = output_size\n",
    "#         self.rnn = nn.RNN(input_size, hidden_size = output_size, num_layers = 1, batch_first=True)\n",
    "#         #self.fc1 = nn.Linear(input_size, output_size)\n",
    "#           #Network for \"no-trade\"\n",
    "#         # self.fc1 = nn.Sequential(\n",
    "#         #     nn.Linear(input_size,80,bias = True),\n",
    "#         #     nn.Sigmoid(),\n",
    "#         #     nn.Linear(80,40),\n",
    "#         #     nn.Sigmoid(),\n",
    "#         #     nn.Linear(40,20),\n",
    "#         #     nn.Sigmoid(),\n",
    "#         #     nn.Linear(20,output_size),\n",
    "#         #     nn.Sigmoid()\n",
    "#         # )\n",
    "#         # # # self.fc2 = nn.Linear(input_size, output_size)  # Network for \"x-zone\"\n",
    "#         # # self.fc2 = nn.Sequential(\n",
    "#         # #     nn.Linear(input_size,80),\n",
    "#         # #     nn.Tanh(),\n",
    "#         # #     nn.Linear(80,40),\n",
    "#         # #     nn.ReLU(),\n",
    "#         # #     nn.Linear(40,20),\n",
    "#         # #     nn.ReLU(),\n",
    "#         # #     nn.Linear(20,output_size),\n",
    "#         # #     nn.Tanh()\n",
    "#         # # )\n",
    "#         # self.fc2 = nn.Sequential(\n",
    "#         #     nn.Linear(input_size,80,bias = False),\n",
    "#         #     nn.Sigmoid(),\n",
    "#         #     nn.Linear(80,40,bias = False),\n",
    "#         #     nn.Sigmoid(),\n",
    "#         #     nn.Linear(40,20,bias = False),\n",
    "#         #     nn.Sigmoid(),\n",
    "#         #     nn.Linear(20,output_size,bias = False),\n",
    "#         #     nn.Sigmoid()\n",
    "#         # )\n",
    "\n",
    "#         # self.fc1 = nn.Sequential(\n",
    "#         #     nn.Linear(input_size, 80, bias=True),\n",
    "#         #     nn.Tanh(),  # ReLU activation for better sensitivity\n",
    "#         #     #nn.BatchNorm1d(80),  # Batch normalization\n",
    "#         #     nn.Linear(80, 40, bias=True),\n",
    "#         #     nn.Tanh(),  # ReLU activation\n",
    "#         #     #nn.BatchNorm1d(40),  # Batch normalization\n",
    "#         #     nn.Linear(40, 20, bias=True),\n",
    "#         #     nn.Tanh(),  # ReLU activation\n",
    "#         #     #nn.BatchNorm1d(20),  # Batch normalization\n",
    "#         #     nn.Linear(20, output_size),\n",
    "#         #     nn.Sigmoid()\n",
    "#         # )   \n",
    "\n",
    "#         # self.fc2 = nn.Sequential(\n",
    "#         #     nn.Linear(input_size, 80, bias=True),\n",
    "#         #     nn.Tanh(),  # Tanh activation\n",
    "#         #     #nn.BatchNorm1d(80),  # Batch normalization\n",
    "#         #     nn.Linear(80, 40, bias=True),\n",
    "#         #     nn.Tanh(),  # Tanh activation\n",
    "#         #     #nn.BatchNorm1d(40),  # Batch normalization\n",
    "#         #     nn.Linear(40, 20, bias=True),\n",
    "#         #     nn.Tanh(),  # Tanh activation\n",
    "#         #     #nn.BatchNorm1d(20),  # Batch normalization\n",
    "#         #     nn.Linear(20, output_size, bias=True),\n",
    "#         #     nn.Sigmoid()\n",
    "#         # )   \n",
    "\n",
    "#         #self.observed_boundaries = []\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         input_to_nn= x.reshape(-1,N)\n",
    "#         #print(x.shape)\n",
    "#         # out_l = self.fc1(x*1000)\n",
    "#         # out_u = self.fc2(x*1000)\n",
    "#         # print(out_l)\n",
    "#         # print(out_u)\n",
    "#         #print(out.shape)\n",
    "#         # out_no_trade = self.fc1(out)\n",
    "#         # out_x_zone = self.fc2(out)\n",
    "#         #print(out_u.shape)\n",
    "#         # lower_b = out_l.reshape(-1,T,n)\n",
    "#         # upper_b = out_u.reshape(-1,T,n)\n",
    "#         #print(x.shape)\n",
    "#         # lower_b = torch.tanh(self.fc1(x))\n",
    "#         # upper_b = torch.tanh(self.fc2(x))\n",
    "#         #upper_b = torch.maximum(lower_b,upper_b)\n",
    "#         out,_ = self.rnn(x)\n",
    "#         out = torch.sigmoid(x)\n",
    "#         out_l = out[:,:,:n]\n",
    "#         out_u = out[:,:,n:]\n",
    "#         return torch.tensor(out_l,requires_grad=True),torch.tensor(out_u,requires_grad=True)\n",
    "\n",
    "# # Example usage of the custom loss function and RNN cell\n",
    "# input_size = N  # Replace with the appropriate input size\n",
    "# #hidden_size = 150  # Replace with the appropriate hidden size\n",
    "# output_size = 2*n # 2 output units, \"no-trade\" and \"x-zone\" decisions\n",
    "# crra_coefficient = 1  # CRRA coefficient, adjust as needed\n",
    "\n",
    "# rnn_cell = CustomRNNCell(input_size, output_size)\n",
    "# custom_loss = CustomLoss(crra_coefficient)\n",
    "\n",
    "# # Generate some example data\n",
    "# #input_data = torch.randn(T, input_size)  # (batch_size, sequence_length, input_size)\n",
    "# #target_data = torch.randn(T, output_size)  # (batch_size, sequence_length, output_size)\n",
    "# #regime_probs = torch.rand(T,2)  # Probability vector over regimes\n",
    "\n",
    "# n_samples = 1000\n",
    "# input_data = []\n",
    "# return_samples= []\n",
    "# cnt0 = 0\n",
    "# plot_x = []\n",
    "# for i in range(n_samples):\n",
    "#     sample = generate_monte_carlo_sample()\n",
    "#     if(sample[0][0]==0):\n",
    "#         cnt0+=1\n",
    "#     returns_for_this_sample = []\n",
    "#     for time in range(T):\n",
    "#         returns_for_this_sample.append(sample[time][1])\n",
    "#     return_samples.append(returns_for_this_sample)\n",
    "#     #return_samples.append()\n",
    "#     initial_p = np.random.rand(N)\n",
    "#     plot_x.append(initial_p[0])\n",
    "#     initial_p/=np.sum(initial_p)\n",
    "#     input_to_rnn = [initial_p]\n",
    "#     for time in range(T-1):\n",
    "#         p = input_to_rnn[-1]\n",
    "#         p_new = updateBelief_for_RNN(sample[time][1],p)\n",
    "#         #p_new = closest_probability_distn(p_new)[1]\n",
    "#         plot_x.append(p_new[0])\n",
    "#         input_to_rnn.append(p_new)\n",
    "#     input_data.append(input_to_rnn)\n",
    "\n",
    "# print(cnt0)\n",
    "# print(len(plot_x))\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(plot_x,bins = 100)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Input data: \",input_data[0])\n",
    "# print(\"Return_Samples: \",return_samples[0])\n",
    "# input_data = torch.tensor(input_data,dtype= torch.float32,requires_grad=True)\n",
    "# #return_samples = torch.tensor(return_samples,dtype = torch.float32)\n",
    "\n",
    "# optimizer = optim.Adam(rnn_cell.parameters(), lr=0.0001)\n",
    "# #print(reverse_index)\n",
    "# # Forward pass and compute lossnp.ones(n+1)/(n+1)\n",
    "# for iter in range(10):\n",
    "#     lb,ub = rnn_cell(input_data)\n",
    "#     #print(lb.shape)\n",
    "#     #print(lb,ub)\n",
    "#     initial_wealth = torch.scalar_tensor(1000,requires_grad=True)\n",
    "#     initial_portfolio = torch.rand(n+1,requires_grad=True)\n",
    "#     initial_portfolio = initial_portfolio/torch.sum(initial_portfolio)\n",
    "#     loss = custom_loss(initial_wealth= initial_wealth,initial_portfolio = initial_portfolio,upper_b = ub,lower_b = lb,returns = np.array(return_samples),input_data = input_data)\n",
    "\n",
    "#     print(\"Loss: \",loss)\n",
    "#     # You can then use these losses to perform backpropagation and optimize your RNN cell using an optimizer like Adam.\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# x_values = []\n",
    "# upper_b = []\n",
    "# lower_b = []\n",
    "# portfolio_values = []\n",
    "# for p in possible_probabities:\n",
    "#     p_normal = p[0]\n",
    "#     x_values.append(p_normal)\n",
    "#     pi_star = optimal_pi_star[(reverse_index[tuple(p)],1)]\n",
    "#     portfolio_values.append(pi_star[0])\n",
    "#     l_b,u_b = rnn_cell(torch.tensor([[p]*T],dtype = torch.float32))\n",
    "#     lower_b.append(max(-1.0,(pi_star[0]-l_b[0][1][0]).detach().numpy()))\n",
    "#     upper_b.append(min(1.0,(pi_star[0]+u_b[0][1][0]).detach().numpy()))\n",
    "# plt.plot(x_values,lower_b,color= 'g')\n",
    "# plt.plot(x_values,upper_b,color = 'b')\n",
    "# plt.plot(x_values,portfolio_values,color = 'r')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "# # Define your parameters\n",
    "# import tensorflow as tf\n",
    "\n",
    "def closest_probability_distn_TF(p_in):\n",
    "    lowest_norm = float('inf')  # Set to positive infinity initially\n",
    "    ind = 0\n",
    "    p_in = p_in.numpy()  # Convert to NumPy array\n",
    "    p_in_tf = tf.convert_to_tensor(p_in, dtype=tf.float32)  # Convert back to TensorFlow tensor\n",
    "\n",
    "    # Iterate through the set and calculate the norm for each element\n",
    "    for i, array in enumerate(possible_probabities):\n",
    "        array_tf = tf.convert_to_tensor(array, dtype=tf.float32)\n",
    "        norm = tf.norm(p_in_tf - array_tf, ord='euclidean')  # Calculate the Euclidean norm\n",
    "        if norm < lowest_norm:\n",
    "            lowest_norm = norm\n",
    "            closest_array = array\n",
    "            ind = i\n",
    "\n",
    "    return ind, closest_array\n",
    "\n",
    "# transaction_rate = 0.005\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# def newWealth_withTC(W, r, pi_pre, pi_new):\n",
    "#     W = tf.constant(W, dtype=tf.float32)\n",
    "#     r = tf.constant(r, dtype=tf.float32)\n",
    "#     pi_pre = tf.constant(pi_pre, dtype=tf.float32)\n",
    "#     pi_new = tf.constant(pi_new, dtype=tf.float32)\n",
    "\n",
    "#     n = tf.shape(r)[0] - 1\n",
    "#     W_new = tf.Variable(0.0, dtype=tf.float32)\n",
    "#     #print(W,r,pi_pre,pi_new)\n",
    "#     # Accumulate values without in-place operations\n",
    "#     for i in tf.range(n + 1):\n",
    "#         W_new.assign_add(W * pi_pre[i] * (1 + r[i]))\n",
    "\n",
    "#     tc = transaction_rate * tf.norm(pi_new - pi_pre, ord=1)\n",
    "\n",
    "#     # Update W_new with the transaction cost\n",
    "#     W_new.assign_sub(W_new*tc)\n",
    "\n",
    "#     return W_new\n",
    "\n",
    "# # Define your custom loss function\n",
    "\n",
    "# class CustomLossTF(tf.keras.losses.Loss):\n",
    "#     def __init__(self, crra_coefficient):\n",
    "#         super(CustomLossTF, self).__init__()\n",
    "#         self.crra_coefficient = crra_coefficient\n",
    "\n",
    "#     def __call__(self, initial_w, initial_p, upper_b, lower_b, returns, input_data):\n",
    "#         input_size = upper_b.shape[0]\n",
    "#         total_loss = 0.0\n",
    "#         print(input_size)\n",
    "#         for _ in range(input_size):\n",
    "#             print(_)\n",
    "#             wealth = [tf.constant(initial_w,dtype = tf.float32)]\n",
    "#             portfolio = [tf.constant(initial_p,dtype = tf.float32)]\n",
    "\n",
    "#             for i in range(T):\n",
    "#                 w = wealth[-1]\n",
    "#                 pi = portfolio[-1]\n",
    "#                 pi_new = tf.identity(pi)[:-1]\n",
    "\n",
    "#                 # Your logic for updating pi_new and calculating wealth goes here\n",
    "#                 closest_p_ind, __ = closest_probability_distn_TF(input_data[_, i])\n",
    "#                 pi_star = tf.convert_to_tensor(optimal_pi_star[(closest_p_ind, i)],dtype = tf.float32)\n",
    "#                 #pi_star_arrays.append(pi_star)\n",
    "#                 #print(pi_star)\n",
    "#                 pi_star = pi_star[:-1]\n",
    "\n",
    "#                 u_b = upper_b[_, i]\n",
    "#                 l_b = lower_b[_, i]\n",
    "\n",
    "#                 u_b = tf.minimum(tf.ones(n, dtype=tf.float32), pi_star + u_b)\n",
    "#                 l_b = tf.maximum(-tf.ones(n, dtype=tf.float32), pi_star - l_b)\n",
    "#                 #print(l_b,u_b)\n",
    "#                 # Your logic for updating u_b, l_b, and pi_new goes here\n",
    "#                 pi_new = tf.maximum(l_b, tf.minimum(u_b, pi_new))\n",
    "#                 risk_free_allocation = 1 - tf.reduce_sum(pi_new)\n",
    "#                 pi_new = tf.concat([pi_new, [risk_free_allocation]], axis=0)\n",
    "\n",
    "#                 portfolio.append(tf.Variable(pi_new, dtype=tf.float32))\n",
    "#                 new_wealth = tf.convert_to_tensor(newWealth_withTC(W=w, r=returns[_, i], pi_pre=pi, pi_new=pi_new),dtype= tf.float32)\n",
    "#                 #print(new_wealth)\n",
    "#                 wealth.append(new_wealth)\n",
    "\n",
    "\n",
    "#             loss = -tf.math.pow(wealth[-1], self.crra_coefficient) / self.crra_coefficient\n",
    "#             total_loss += loss\n",
    "#             print(wealth,portfolio)\n",
    "\n",
    "#         return total_loss / input_size\n",
    "\n",
    "# # Define your RNN cell with two neural networks\n",
    "# class CustomRNNCell(tf.keras.layers.Layer):\n",
    "#     def __init__(self, output_size):\n",
    "#         super(CustomRNNCell, self).__init__()\n",
    "#         self.rnn = tf.keras.layers.SimpleRNN(output_size, return_sequences=True)\n",
    "#         self.fc = tf.keras.layers.Dense(2 * n, activation='sigmoid')\n",
    "\n",
    "#     def __call__(self, x):\n",
    "#         out = self.rnn(x)\n",
    "#         out_l, out_u = tf.split(self.fc(out), num_or_size_splits=2, axis=-1)\n",
    "#         return out_l, out_u\n",
    "\n",
    "\n",
    "\n",
    "# n_samples = 1\n",
    "# input_data = []\n",
    "# return_samples= []\n",
    "# cnt0 = 0\n",
    "# plot_x = []\n",
    "# for i in range(n_samples):\n",
    "#     sample = generate_monte_carlo_sample()\n",
    "#     if(sample[0][0]==0):\n",
    "#         cnt0+=1\n",
    "#     returns_for_this_sample = []\n",
    "#     for time in range(T):\n",
    "#         returns_for_this_sample.append(sample[time][1])\n",
    "#     return_samples.append(returns_for_this_sample)\n",
    "#     #return_samples.append()\n",
    "#     initial_p = np.random.rand(N)\n",
    "#     plot_x.append(initial_p[0])\n",
    "#     initial_p/=np.sum(initial_p)\n",
    "#     input_to_rnn = [initial_p]\n",
    "#     for time in range(T-1):\n",
    "#         p = input_to_rnn[-1]\n",
    "#         p_new = updateBelief_for_RNN(sample[time][1],p)\n",
    "#         #p_new = closest_probability_distn(p_new)[1]\n",
    "#         plot_x.append(p_new[0])\n",
    "#         input_to_rnn.append(p_new)\n",
    "#     input_data.append(input_to_rnn)\n",
    "\n",
    "# print(cnt0)\n",
    "# print(len(plot_x))\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(plot_x,bins = 100)\n",
    "# plt.show()\n",
    "\n",
    "# input_data = tf.constant(input_data, dtype=tf.float32)\n",
    "# return_samples = tf.constant(return_samples, dtype=tf.float32)\n",
    "\n",
    "# # Create the model\n",
    "# rnn_cell = CustomRNNCell(output_size=2 * n)\n",
    "# custom_loss = CustomLossTF(crra_coefficient=1)\n",
    "\n",
    "# # Create an optimizer\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# # Training loop\n",
    "# for iter in range(10):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         lb, ub = rnn_cell(input_data)\n",
    "#         print(lb,ub)\n",
    "#         initial_wealth = tf.constant(1000.0,dtype = tf.float32)\n",
    "#         initial_portfolio = tf.constant(np.random.rand(n+1),dtype = tf.float32)\n",
    "#         initial_portfolio /= tf.reduce_sum(initial_portfolio)\n",
    "#         loss = custom_loss(\n",
    "#             initial_w=initial_wealth,\n",
    "#             initial_p=initial_portfolio,\n",
    "#             upper_b=ub,\n",
    "#             lower_b=lb,\n",
    "#             returns=return_samples,\n",
    "#             input_data=input_data\n",
    "#         )\n",
    "#     print(\"Loss: \", loss)\n",
    "#     grads = tape.gradient(loss, rnn_cell.trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(grads, rnn_cell.trainable_variables))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0010958149, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010961356, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010957164, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010961179, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010973088, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010969139, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010966304, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0011001158, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010987376, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010968837, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define your constants\n",
    "transaction_rate = 0.015\n",
    "crra_coefficient = -1  # CRRA coefficient, adjust as needed\n",
    "\n",
    "def newWealthWithTC(W, r, pi_pre, pi_new):\n",
    "    W_new = tf.reduce_sum(W * pi_pre * (1 + r))\n",
    "    W_new = W_new - W_new * transaction_rate * tf.norm(pi_new - pi_pre, ord=1)\n",
    "    #print(W,r,pi_pre,pi_new,W_new)\n",
    "    return W_new\n",
    "\n",
    "# Define the custom loss function\n",
    "def custom_loss(initial_wealth, initial_portfolio, upper_b, lower_b, returns):\n",
    "    input_size = tf.shape(upper_b)[0]\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for _ in range(input_size):\n",
    "        wealth = [tf.constant([initial_wealth], dtype=tf.float32)]\n",
    "        portfolio = [tf.constant(initial_portfolio, dtype=tf.float32)]\n",
    "\n",
    "        #constraint_loss = 0.0\n",
    "        for i in range(T):\n",
    "            w = wealth[-1]\n",
    "            pi = portfolio[-1]\n",
    "            pi_new = tf.identity(pi)[:-1]\n",
    "\n",
    "            # constraint_loss += tf.reduce_sum(tf.nn.relu(l_b - u_b)) * 1000.0\n",
    "\n",
    "            # pi_new = tf.maximum(l_b, tf.minimum(u_b, pi_new))\n",
    "            # risk_free_allocation = 1 - tf.reduce_sum(pi_new)\n",
    "\n",
    "            closest_p_ind, __ = closest_probability_distn_TF(input_data[_, i])\n",
    "            pi_star = tf.convert_to_tensor(optimal_pi_star[(closest_p_ind, i)],dtype = tf.float32)\n",
    "            #pi_star_arrays.append(pi_star)\n",
    "            #print(pi_star)\n",
    "            pi_star = pi_star[:-1]\n",
    "            u_b = upper_b[_, i]\n",
    "            l_b = lower_b[_, i]\n",
    "            u_b = tf.minimum(tf.ones(n, dtype=tf.float32), pi_star + u_b)\n",
    "            l_b = tf.maximum(-tf.ones(n, dtype=tf.float32), pi_star - l_b)\n",
    "            #print(l_b,u_b)\n",
    "            # Your logic for updating u_b, l_b, and pi_new goes here\n",
    "            pi_new = tf.maximum(l_b, tf.minimum(u_b, pi_new))\n",
    "            risk_free_allocation = 1 - tf.reduce_sum(pi_new)\n",
    "            pi_new = tf.concat([pi_new, [risk_free_allocation]], axis=0)\n",
    "            #pi_new = tf.concat([pi_new, [risk_free_allocation]], axis=0)\n",
    "            portfolio.append(pi_new)\n",
    "\n",
    "            new_wealth = newWealthWithTC(w, returns[_][i], pi, pi_new)\n",
    "            wealth.append(new_wealth)\n",
    "        # print(wealth)\n",
    "        # print(portfolio)\n",
    "        loss = -((wealth[-1] ** crra_coefficient) / crra_coefficient) \n",
    "        #print(wealth)\n",
    "        total_loss += loss\n",
    "\n",
    "    return total_loss / tf.cast(input_size, dtype=tf.float32)\n",
    "\n",
    "# Define the RNN cell with two neural networks\n",
    "class CustomRNNCell(tf.keras.layers.Layer):\n",
    "    # def __init__(self, input_size, output_size):\n",
    "    #     super(CustomRNNCell, self).__init__()\n",
    "    #     self.input_size = input_size\n",
    "    #     self.output_size = output_size\n",
    "\n",
    "    #     self.fc1 = tf.keras.Sequential([\n",
    "    #         tf.keras.layers.Dense(80, activation='tan h'),\n",
    "    #         tf.keras.layers.Dense(40, activation='tanh'),\n",
    "    #         tf.keras.layers.Dense(20, activation='tanh'),\n",
    "    #         tf.keras.layers.Dense(output_size, activation='tanh')\n",
    "    #     ])\n",
    "\n",
    "    # def call(self, x):\n",
    "    #     out = self.fc1(x)\n",
    "    #     lower_b = out\n",
    "    #     upper_b = out\n",
    "    #     return lower_b, upper_b\n",
    "    def __init__(self, output_size):\n",
    "        super(CustomRNNCell, self).__init__()\n",
    "        #self.rnn = tf.keras.layers.SimpleRNN(output_size, return_sequences=True)\n",
    "        self.fc1 = tf.keras.layers.Dense(n, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "        self.fc2 = tf.keras.layers.Dense(n, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "    def call(self, x):\n",
    "        # out = self.rnn(x)\n",
    "        # out_l, out_u = tf.split(self.fc(out), num_or_size_splits=2, axis=-1)\n",
    "        out_l = self.fc1(x)\n",
    "        out_u = self.fc2(x)\n",
    "        return out_l, out_u\n",
    "\n",
    "# # Generate some example data\n",
    "# n_samples = 1\n",
    "# input_data = []\n",
    "# return_samples = []\n",
    "\n",
    "# for i in range(n_samples):\n",
    "#     sample = generate_monte_carlo_sample()  # You should implement this function\n",
    "#     returns_for_this_sample = [sample[time][1] for time in range(T)]\n",
    "#     return_samples.append(returns_for_this_sample)\n",
    "\n",
    "#     initial_p = np.random.rand(N)\n",
    "#     initial_p /= np.sum(initial_p)\n",
    "#     input_to_rnn = [initial_p]\n",
    "\n",
    "#     for time in range(T - 1):\n",
    "#         p = input_to_rnn[-1]\n",
    "#         p_new = updateBelief_for_RNN(sample[time][1], p)  # You should implement this function\n",
    "#         input_to_rnn.append(p_new)\n",
    "\n",
    "#     input_data.append(input_to_rnn)\n",
    "\n",
    "# input_data = tf.constant(input_data, dtype=tf.float32)\n",
    "# return_samples = tf.constant(return_samples, dtype=tf.float32)\n",
    "n_samples = 200\n",
    "input_data = []\n",
    "return_samples= []\n",
    "cnt0 = 0\n",
    "plot_x = []\n",
    "for i in range(n_samples):\n",
    "    sample = generate_monte_carlo_sample()\n",
    "    if(sample[0][0]==0):\n",
    "        cnt0+=1\n",
    "    returns_for_this_sample = []\n",
    "    for time in range(T):\n",
    "        returns_for_this_sample.append(sample[time][1])\n",
    "    return_samples.append(returns_for_this_sample)\n",
    "    #return_samples.append()\n",
    "    initial_p = np.random.rand(N)\n",
    "    initial_p/=np.sum(initial_p)\n",
    "    initial_p = closest_probability_distn(initial_p)[1]\n",
    "    plot_x.append(initial_p[0])\n",
    "    input_to_rnn = [initial_p]\n",
    "    for time in range(T-1):\n",
    "        p = input_to_rnn[-1]\n",
    "        p_new,__ = updateBelief(sample[time][1],p)\n",
    "        p_new = closest_probability_distn(p_new)[1]\n",
    "        plot_x.append(p_new[0])\n",
    "        input_to_rnn.append(p_new)\n",
    "    input_data.append(input_to_rnn)\n",
    "\n",
    "print(cnt0)\n",
    "print(len(plot_x))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(plot_x,bins = 100)\n",
    "plt.show()\n",
    "\n",
    "input_data = tf.constant(input_data, dtype=tf.float32)\n",
    "return_samples = tf.constant(return_samples, dtype=tf.float32)\n",
    "# Create the RNN cell and optimizer\n",
    "input_size = N\n",
    "output_size = n\n",
    "rnn_cell_57 = CustomRNNCell(output_size)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "#Training loop\n",
    "for iter in range(10):\n",
    "    with tf.GradientTape() as tape:\n",
    "        lb, ub = rnn_cell_57(input_data)\n",
    "        initial_wealth = 1000\n",
    "        initial_portfolio = np.random.rand(n + 1).astype(np.float32)\n",
    "        initial_portfolio /= np.sum(initial_portfolio)\n",
    "        loss = custom_loss(initial_wealth, initial_portfolio, ub, lb, return_samples)\n",
    "\n",
    "    gradients = tape.gradient(loss, rnn_cell_57.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, rnn_cell_57.trainable_variables))\n",
    "\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.02 0.98] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.04 0.96] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.06 0.94] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.08 0.92] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.1 0.9] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.12 0.88] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.14 0.86] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.16 0.84] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.18 0.82] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.2 0.8] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.22 0.78] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.24 0.76] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.26 0.74] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.28 0.72] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.3 0.7] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.32 0.68] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.34 0.66] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.36 0.64] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.38 0.62] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "[0.4 0.6] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.02052183, shape=(), dtype=float32)\n",
      "[0.42 0.58] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.05167709, shape=(), dtype=float32)\n",
      "[0.44 0.56] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.082832314, shape=(), dtype=float32)\n",
      "[0.46 0.54] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.11398754, shape=(), dtype=float32)\n",
      "[0.48 0.52] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.14514278, shape=(), dtype=float32)\n",
      "[0.5 0.5] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.176298, shape=(), dtype=float32)\n",
      "[0.52 0.48] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.2074532, shape=(), dtype=float32)\n",
      "[0.54 0.46] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.23860846, shape=(), dtype=float32)\n",
      "[0.56 0.44] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.2697637, shape=(), dtype=float32)\n",
      "[0.58 0.42] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.30091888, shape=(), dtype=float32)\n",
      "[0.6 0.4] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.33207417, shape=(), dtype=float32)\n",
      "[0.62 0.38] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.36322936, shape=(), dtype=float32)\n",
      "[0.64 0.36] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.39438456, shape=(), dtype=float32)\n",
      "[0.66 0.34] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.42553982, shape=(), dtype=float32)\n",
      "[0.68 0.32] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.45669508, shape=(), dtype=float32)\n",
      "[0.7 0.3] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.4878503, shape=(), dtype=float32)\n",
      "[0.72 0.28] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.51900554, shape=(), dtype=float32)\n",
      "[0.74 0.26] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.55016077, shape=(), dtype=float32)\n",
      "[0.76 0.24] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.58131593, shape=(), dtype=float32)\n",
      "[0.78 0.22] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.6124712, shape=(), dtype=float32)\n",
      "[0.8 0.2] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.64362645, shape=(), dtype=float32)\n",
      "[0.82 0.18] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.6747817, shape=(), dtype=float32)\n",
      "[0.84 0.16] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.7059369, shape=(), dtype=float32)\n",
      "[0.86 0.14] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.73709214, shape=(), dtype=float32)\n",
      "[0.88 0.12] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.76824737, shape=(), dtype=float32)\n",
      "[0.9 0.1] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.79940253, shape=(), dtype=float32)\n",
      "[0.92 0.08] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.8305578, shape=(), dtype=float32)\n",
      "[0.94 0.06] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.86171305, shape=(), dtype=float32)\n",
      "[0.96 0.04] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.8928683, shape=(), dtype=float32)\n",
      "[0.98 0.02] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.9240235, shape=(), dtype=float32)\n",
      "[1. 0.] tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(0.95517874, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_values = []\n",
    "upper_b = []\n",
    "lower_b = []\n",
    "portfolio_values = []\n",
    "for p in possible_probabities:\n",
    "    p_normal = p[0]\n",
    "    x_values.append(p_normal)\n",
    "    pi_star = optimal_pi_star[(reverse_index[tuple(p)],2)]\n",
    "    portfolio_values.append(pi_star[0])\n",
    "    l_b,u_b = rnn_cell_57(tf.constant([[p]*T],dtype = tf.float32))\n",
    "    print(p,l_b[0][1][0],u_b[0][1][0])\n",
    "    lower_b.append(max(-1.0,(pi_star[0]-l_b[0][2][0])))\n",
    "    upper_b.append(min(1.0,(pi_star[0]+u_b[0][2][0])))\n",
    "plt.plot(x_values,lower_b,color= 'g')\n",
    "plt.plot(x_values,upper_b,color = 'b')\n",
    "plt.plot(x_values,portfolio_values,color = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"No GPU detected. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rnn_cell' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\91897\\OneDrive - iitkgp.ac.in\\Desktop\\IIT Khargpur\\seventh sem\\BTP\\Code\\code.ipynb Cell 20\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/91897/OneDrive%20-%20iitkgp.ac.in/Desktop/IIT%20Khargpur/seventh%20sem/BTP/Code/code.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     temp_input[\u001b[39m0\u001b[39m][j] \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(p,dtype \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/91897/OneDrive%20-%20iitkgp.ac.in/Desktop/IIT%20Khargpur/seventh%20sem/BTP/Code/code.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m temp_input\u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(temp_input,dtype \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/91897/OneDrive%20-%20iitkgp.ac.in/Desktop/IIT%20Khargpur/seventh%20sem/BTP/Code/code.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m lb, ub \u001b[39m=\u001b[39m rnn_cell(temp_input)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/91897/OneDrive%20-%20iitkgp.ac.in/Desktop/IIT%20Khargpur/seventh%20sem/BTP/Code/code.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m lb \u001b[39m=\u001b[39m lb[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/91897/OneDrive%20-%20iitkgp.ac.in/Desktop/IIT%20Khargpur/seventh%20sem/BTP/Code/code.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m ub \u001b[39m=\u001b[39m ub[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rnn_cell' is not defined"
     ]
    }
   ],
   "source": [
    "#temp_input= tf.constant(temp_input,dtype = tf.float32)\n",
    "for p in possible_probabities:\n",
    "    print(p)\n",
    "    temp_input = np.zeros((1,T,N))\n",
    "    for j in range(T):\n",
    "        temp_input[0][j] = tf.constant(p,dtype = tf.float32)\n",
    "    temp_input= tf.constant(temp_input,dtype = tf.float32)\n",
    "    lb, ub = rnn_cell(temp_input)\n",
    "    lb = lb[0][0][0]\n",
    "    ub = ub[0][0][0]\n",
    "    print(lb,ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xpoints = [x[0] for x in possible_probabities]\n",
    "ypoints = [optimal_pi_star[_,2][0] for _ in range(len(possible_probabities))]\n",
    "\n",
    "plt.plot(xpoints,ypoints)\n",
    "plt.show()\n",
    "\n",
    "print([optimal_pi_star[_,2] for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb,ub = rnn_cell(input_data)\n",
    "print(lb[0])\n",
    "print(ub[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "transaction_rate = 0.1\n",
    "\n",
    "def newWealth_withTC(W, r,pi_pre, pi_new):\n",
    "    # print(pi_new)\n",
    "    # print(pi_pre)\n",
    "    W = np.multiply(pi_pre,1+r)\n",
    "    diff = pi_pre-pi_new\n",
    "    W_new = W - transaction_rate * tf.norm(diff, ord=1)\n",
    "    return W_new\n",
    "\n",
    "class CustomLoss(keras.losses.Loss):\n",
    "    def __init__(self, crra_coefficient, **kwargs):\n",
    "        super(CustomLoss, self).__init__(**kwargs)\n",
    "        self.crra_coefficient = crra_coefficient\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        initial_wealth, initial_portfolio = y_true\n",
    "        lower_b, upper_b = y_pred\n",
    "        wealth = [tf.convert_to_tensor(initial_wealth)]\n",
    "        portfolio = [tf.convert_to_tensor(initial_portfolio)]\n",
    "\n",
    "        for i in range(T):\n",
    "            w = wealth[-1]\n",
    "            pi = portfolio[-1]\n",
    "            pi_new = tf.identity(pi)\n",
    "            pi_new = pi_new[:-1]\n",
    "            u_b = upper_b[0][i]\n",
    "            l_b = lower_b[0][i]\n",
    "            print(u_b)\n",
    "            print(l_b)\n",
    "            print(pi_new)\n",
    "            pi_new = tf.maximum(l_b,tf.minimum(u_b,pi_new))\n",
    "\n",
    "\n",
    "            risk_free_allocation = tf.constant(1.0) - tf.reduce_sum(pi_new)\n",
    "            pi_new = tf.concat([pi_new, [risk_free_allocation]], axis=0)\n",
    "            portfolio.append(pi_new)\n",
    "            new_wealth = newWealth_withTC(w, pi, pi_new)\n",
    "            wealth.append(new_wealth)\n",
    "\n",
    "        final_wealth = wealth[-1]\n",
    "        loss = -tf.pow(final_wealth, gamma) / gamma\n",
    "\n",
    "        return loss\n",
    "\n",
    "# Define your RNN cell as a custom Keras layer\n",
    "class CustomRNNCell(keras.layers.Layer):\n",
    "    def __init__(self, output_size, **kwargs):\n",
    "        super(CustomRNNCell, self).__init__(**kwargs)\n",
    "        self.output_size = output_size\n",
    "        self.rnn = keras.layers.RNN(keras.layers.SimpleRNNCell(output_size), return_sequences=True, batch_size = 1)\n",
    "        self.lower_bound_dense = keras.layers.Dense(n)\n",
    "        self.upper_bound_dense = keras.layers.Dense(n)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.rnn(x)\n",
    "        lower_b = self.lower_bound_dense(out)\n",
    "        upper_b = self.upper_bound_dense(out)\n",
    "        return lower_b, upper_b\n",
    "\n",
    "# Example usage of the custom loss function and RNN cell\n",
    "N = 2\n",
    "n = 1\n",
    "T = 5\n",
    "input_size = N  # Replace with the appropriate input size\n",
    "output_size = 2 * n  # 2 output units, \"no-trade\" and \"x-zone\" decisions\n",
    "crra_coefficient = -1  # CRRA coefficient, adjust as needed\n",
    "\n",
    "\n",
    "rnn_cell = CustomRNNCell(output_size)\n",
    "custom_loss = CustomLoss(crra_coefficient)\n",
    "\n",
    "# Generate some example data\n",
    "input_data = np.random.randn(1,T, N)  # (sequence_length, input_size)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Forward pass and compute loss\n",
    "for iter in range(5):\n",
    "    lb, ub = rnn_cell(input_data)\n",
    "    print(lb, ub)\n",
    "    \n",
    "    initial_wealth = 1\n",
    "    initial_portfolio = np.ones(n+1,dtype=\"float32\") / (n + 1)\n",
    "    \n",
    "    loss = custom_loss([initial_wealth, initial_portfolio], [lb,ub])\n",
    "\n",
    "    print(loss)\n",
    "    \n",
    "    grads = custom_loss.gradient([initial_wealth, initial_portfolio, ub, lb], [0])\n",
    "    optimizer.apply_gradients(zip(grads, rnn_cell.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the RNN parameters\n",
    "input_size = 10  # Input feature size\n",
    "hidden_size = 20  # Hidden state size\n",
    "num_layers = 2  # Number of RNN layers\n",
    "sequence_length = 5  # Length of the input sequence\n",
    "batch_size = 3  # Number of sequences in a batch\n",
    "\n",
    "# Create sample input data\n",
    "input_data = torch.randn(batch_size, sequence_length, input_size)\n",
    "\n",
    "# Define the RNN layer\n",
    "rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "# Pass the input data through the RNN\n",
    "output, hidden = rnn(input_data)\n",
    "\n",
    "# 'output' contains the output at each time step\n",
    "# 'hidden' contains the hidden state at the final time step\n",
    "\n",
    "# Print the shapes of output and hidden\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Hidden shape:\", hidden.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameters, including the output size (2 * n)\n",
    "n = 5  # You can change the value of n according to your problem\n",
    "output_size = 2 * n\n",
    "\n",
    "# Define the custom RNN cell\n",
    "class CustomRNNCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_size):\n",
    "        super(CustomRNNCell, self).__init__()\n",
    "        self.rnn = tf.keras.layers.SimpleRNN(output_size, return_sequences=True)\n",
    "        self.fc = tf.keras.layers.Dense(2 * n, activation='sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.rnn(x)\n",
    "        out_l, out_u = tf.split(self.fc(out), num_or_size_splits=2, axis=-1)\n",
    "        return out_l, out_u\n",
    "\n",
    "# Create an instance of the custom RNN cell\n",
    "rnn_cell = CustomRNNCell(output_size)\n",
    "\n",
    "# Define some input sequences for testing\n",
    "input_seq1 = tf.constant([[[0.2, 0.8], [0.5, 0.5], [0.7, 0.3]]], dtype=tf.float32)  # Example input 1\n",
    "input_seq2 = tf.constant([[[0.6, 0.4], [0.4, 0.6], [0.1, 0.9]]], dtype=tf.float32)  # Example input 2\n",
    "input_seq3 = tf.constant([[[0.3, 0.7], [0.2, 0.8], [0.9, 0.1]]], dtype=tf.float32)  # Example input 3\n",
    "\n",
    "# Obtain initial outputs for the input sequences\n",
    "initial_outputs1 = rnn_cell(input_seq1)\n",
    "initial_outputs2 = rnn_cell(input_seq2)\n",
    "initial_outputs3 = rnn_cell(input_seq3)\n",
    "\n",
    "# Print the initial outputs\n",
    "print(\"Initial Outputs for Input Sequence 1:\")\n",
    "print(\"Lower Bounds:\")\n",
    "print(initial_outputs1[0].numpy())\n",
    "print(\"Upper Bounds:\")\n",
    "print(initial_outputs1[1].numpy())\n",
    "print()\n",
    "\n",
    "print(\"Initial Outputs for Input Sequence 2:\")\n",
    "print(\"Lower Bounds:\")\n",
    "print(initial_outputs2[0].numpy())\n",
    "print(\"Upper Bounds:\")\n",
    "print(initial_outputs2[1].numpy())\n",
    "print()\n",
    "\n",
    "print(\"Initial Outputs for Input Sequence 3:\")\n",
    "print(\"Lower Bounds:\")\n",
    "print(initial_outputs3[0].numpy())\n",
    "print(\"Upper Bounds:\")\n",
    "print(initial_outputs3[1].numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
